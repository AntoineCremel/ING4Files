{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6 : Hand written digits recognition\n",
    "\n",
    "## First step : loading and processing the data\n",
    "Load the images into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 400 entries, Pixel_0 to Pixel_399\n",
      "dtypes: float64(395), int64(5)\n",
      "memory usage: 15.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>Pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_390</th>\n",
       "      <th>Pixel_391</th>\n",
       "      <th>Pixel_392</th>\n",
       "      <th>Pixel_393</th>\n",
       "      <th>Pixel_394</th>\n",
       "      <th>Pixel_395</th>\n",
       "      <th>Pixel_396</th>\n",
       "      <th>Pixel_397</th>\n",
       "      <th>Pixel_398</th>\n",
       "      <th>Pixel_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pixel_0  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  Pixel_7  \\\n",
       "0        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Pixel_8  Pixel_9    ...      Pixel_390  Pixel_391  Pixel_392  Pixel_393  \\\n",
       "0      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "1      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "2      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "3      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "4      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Pixel_394  Pixel_395  Pixel_396  Pixel_397  Pixel_398  Pixel_399  \n",
       "0        0.0        0.0        0.0        0.0        0.0          0  \n",
       "1        0.0        0.0        0.0        0.0        0.0          0  \n",
       "2        0.0        0.0        0.0        0.0        0.0          0  \n",
       "3        0.0        0.0        0.0        0.0        0.0          0  \n",
       "4        0.0        0.0        0.0        0.0        0.0          0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of a dataframe to hold the images\n",
    "data_set = pd.read_csv(\"image_0.txt\", header=None, names=\\\n",
    "                      [\"Pixel_\"+str(x) for x in range(400)])\n",
    "print(data_set.info())\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the labels to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 401 entries, Label to Pixel_399\n",
      "dtypes: float64(395), int64(6)\n",
      "memory usage: 15.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_390</th>\n",
       "      <th>Pixel_391</th>\n",
       "      <th>Pixel_392</th>\n",
       "      <th>Pixel_393</th>\n",
       "      <th>Pixel_394</th>\n",
       "      <th>Pixel_395</th>\n",
       "      <th>Pixel_396</th>\n",
       "      <th>Pixel_397</th>\n",
       "      <th>Pixel_398</th>\n",
       "      <th>Pixel_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Pixel_0  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  \\\n",
       "0      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Pixel_7  Pixel_8    ...      Pixel_390  Pixel_391  Pixel_392  Pixel_393  \\\n",
       "0      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "1      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "2      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "3      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "4      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Pixel_394  Pixel_395  Pixel_396  Pixel_397  Pixel_398  Pixel_399  \n",
       "0        0.0        0.0        0.0        0.0        0.0          0  \n",
       "1        0.0        0.0        0.0        0.0        0.0          0  \n",
       "2        0.0        0.0        0.0        0.0        0.0          0  \n",
       "3        0.0        0.0        0.0        0.0        0.0          0  \n",
       "4        0.0        0.0        0.0        0.0        0.0          0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[\"Label\"] = pd.read_csv(\"label.txt\", header=None, names=[\"Label\"])\n",
    "# Replace the 10s with actual zeros\n",
    "def ten_to_zero(x):\n",
    "    if x == 10:\n",
    "        return 0\n",
    "    return x\n",
    "data_set[\"Label\"] = data_set[\"Label\"].apply(func=ten_to_zero)\n",
    "# Reorganize the columns so that Label is first on the list\n",
    "cols = data_set.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "data_set = data_set[cols]\n",
    "\n",
    "print(data_set.info())\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, proportion=0.8):\n",
    "    shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_data = shuffled_data[:int(0.8 * shuffled_data.shape[0])]\\\n",
    "            .reset_index(drop=True)\n",
    "    test_data = shuffled_data[int(0.8 * shuffled_data.shape[0]):]\\\n",
    "            .reset_index(drop=True)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Columns: 401 entries, Label to Pixel_399\n",
      "dtypes: float64(395), int64(6)\n",
      "memory usage: 12.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test the split function\n",
    "train_data, test_data = split_train_test(data_set)\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we define the parameters of our model\n",
    "* We define a function to initialize parameteres randomly\n",
    "* Each layer of neurons should have a parameter matrix of shape (m, n) where m is the size of the output of the previous layer (or the size of the input in the case of the first layer) + 1, to add the intercept, and n is the number of neurons in this layer.\n",
    "\n",
    "### Example\n",
    "For instance if we have a network with 400 inputs, 25 neurons in the first layer and 10 in the second, we should have parameters like so : \n",
    "* First layer : (401, 25)\n",
    "* Second layer : (26, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layers, n_inputs=400):\n",
    "    \"\"\"\n",
    "        layers is a list. Each of its item represents one layer, and \n",
    "    the number it contains is the size of that layer. The last layer\n",
    "    should always have the size of the expected output (in our case 10)\n",
    "        Our model will then apply argmax to these 10 numbers to find out \n",
    "    which digit was detected.\n",
    "    \n",
    "        The return value is a dic containing a numpy array for each set\n",
    "    of parameters\n",
    "    \"\"\"\n",
    "    parameters = []\n",
    "    \n",
    "    slices = [n_inputs] + layers\n",
    "    \n",
    "    # We loop throught the number of layers to generate parameters\n",
    "    # matrix of the appropriate size\n",
    "    for i, layer in enumerate(layers):\n",
    "        \n",
    "        parameters.append(\\\n",
    "        np.random.randn((slices[i]+1), slices[i+1]))\n",
    "        parameters[i] = parameters[i] * 0.1\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 25)\n",
      "(26, 10)\n",
      "0.16691384829573086\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "layers = [25, 10]\n",
    "params = initialize_parameters(layers)\n",
    "for row in params:\n",
    "    print(row.shape)\n",
    "    \n",
    "print(params[0][0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the feed forward function\n",
    "This step is just a couple of matrix multiplication, which are easy to implement and run very fast thanks to numpy.\n",
    "\n",
    "To make it work, we must first define the sigmoid function that we will\n",
    "be using for activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.power(1 + np.exp(-x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_batch(batch, params):\n",
    "    \"\"\"\n",
    "        Given a batch of inputs, this function will return an equivalent\n",
    "    batch of outputs. The intermediate values are also returned so they\n",
    "    can be cached for back propagation.\n",
    "    \n",
    "    * Inputs : batch must be a numpy array of shape m * 400 where m\n",
    "    represents the batch size, and 400 is the size of the images\n",
    "    \n",
    "    * Outputs : All of the intermediate and final values of our feed_forward\n",
    "    are contained in results. It is a list of dics.\n",
    "    Each dic contains two entries, Xbarbar which is the sum before the \n",
    "    sigmoid activation function, and F which does contain the activation\n",
    "    function\n",
    "    \"\"\"\n",
    "    # X is the matrix of values taht we will feed to the neural\n",
    "    # network\n",
    "    X = np.copy(batch)\n",
    "    image_size = X.shape[0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    for i, param_matrix in enumerate(params):\n",
    "        results_dic = {}\n",
    "        # We pad the batch with a row of ones to create an intercept\n",
    "        Xbar = np.concatenate((np.ones([X.shape[0], 1]), X), axis=1)\n",
    "        # We store the results from before the multiplication with \n",
    "        # the params for the need of the backpropagation\n",
    "        results_dic[\"pre_multi\"] = Xbar\n",
    "        # Then we multiply the padded batch of vectors with the params\n",
    "        Xbarbar = np.dot(Xbar, param_matrix)\n",
    "        # We cache the results for faster backprop\n",
    "        results_dic[\"pre_activation\"] = Xbarbar\n",
    "        # Then we need to apply the activation function to the product\n",
    "        F = sigmoid(Xbarbar)\n",
    "        # We also store the results from after this operation because\n",
    "        # at this point why not\n",
    "        results_dic[\"post_activation\"] = F\n",
    "        # Finally we put F into X to allow for the next step of the loop\n",
    "        X = F\n",
    "        \n",
    "        results.append(results_dic)\n",
    "        \n",
    "    # Once this loop is completed, we should have our output ready\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 400)\n",
      "(4000, 10)\n",
      "[2 2 2 ... 2 2 3]\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "# Test of the feed_forward function\n",
    "print(train_data.drop([\"Label\"], axis=1).values.shape)\n",
    "X = train_data.drop([\"Label\"], axis=1).values\n",
    "Y = train_data[\"Label\"].values\n",
    "results = feed_forward_batch(X, params)\n",
    "Y_hat = results[-1][\"post_activation\"]\n",
    "print(Y_hat.shape)\n",
    "print(np.argmax(Y_hat, axis=1))\n",
    "print(np.argmax(Y_hat, axis=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the back propagation\n",
    "We are now able to run our model to predict a result. We now need to implement the back propagation algorith to modify the parameters in the direction of the right result.\n",
    "\n",
    "* Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_argmax(x):\n",
    "    \"\"\"\n",
    "    First let's make a function to convert a number between 0 and 9\n",
    "    to a vector of numbers between 0 and 1\n",
    "    \"\"\"\n",
    "    return_value = np.zeros((10))\n",
    "    return_value[x] = 1\n",
    "    return return_value\n",
    "\n",
    "def revert_argmax_vectorized(x):\n",
    "    \"\"\"\n",
    "    x is a numpy vector\n",
    "    \"\"\"\n",
    "    return_value = np.zeros((x.shape[0], 10))\n",
    "    \n",
    "    for i, value in enumerate(x):\n",
    "        return_value[i, value] = 1\n",
    "    \n",
    "    return return_value\n",
    "\n",
    "def compute_SSE(Y_hat, Y):\n",
    "    SE = np.power(Y_hat - Y, 2)\n",
    "    SSE = np.sum(SE)\n",
    "    return SSE\n",
    "\n",
    "def compute_cost(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Y_hat and Y must be (m, 10) dimensional matrices or vectors\n",
    "    \"\"\"\n",
    "    assert Y_hat.shape[1] == 10\n",
    "    cost = Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat)\n",
    "    return np.sum(cost) / Y_hat.shape[0]\n",
    "\n",
    "def accuracy_eval(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Y_hat and Y must be matrices of shape (m, 10) where me is the number of examples\n",
    "    \"\"\"\n",
    "    got_it = 0\n",
    "    for i in range(Y_hat.shape[0]):\n",
    "        if np.argmax(Y_hat[i]) == Y[i]:\n",
    "            got_it += 1\n",
    "            \n",
    "    accuracy = got_it / Y_hat.shape[0]\n",
    "    \n",
    "    return accuracy, got_it\n",
    "\n",
    "def test_model(test_data, model):\n",
    "    X_test = test_data.drop([\"Label\"], axis=1).values\n",
    "    Y_test = test_data[\"Label\"].values\n",
    "\n",
    "    test_results = feed_forward_batch(X_test, model)\n",
    "    \n",
    "    accuracy, _ = accuracy_eval(test_results[-1][\"post_activation\"], Y_test)\n",
    "    print(\"Accuracy : \", accuracy * 100, \"%\")\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Actual back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This part was only for tests nut now I am afraid to delete it please ignore\n",
    "\"\"\"\n",
    "\n",
    "def one_layer_back_propagate(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    * Params must be a numpy matrix containing the parameters for\n",
    "    one layer.\n",
    "    * Results contains the result of a layer\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def back_propagate_custom(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    This function will run backwards through the neural net, computing \n",
    "    the derivatives to modify the parameters according to the learning\n",
    "    rate.\n",
    "    \n",
    "    * Y should be a (batch_size, 10) matrix.\n",
    "    * results contains all of the results from the backpropagation,\n",
    "    layer by layer.\n",
    "    \"\"\"\n",
    "    Y_hat = results[-1][\"post_activation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    ========= IMPORTANT ===========\n",
    "    This version of the function is not generealisable to different\n",
    "    number of layers.\n",
    "    \n",
    "    This function will run backwards through the neural net, computing \n",
    "    the derivatives to modify the parameters according to the learning\n",
    "    rate.\n",
    "    \n",
    "    * Y should be a (batch_size, 10) matrix.\n",
    "    * results contains all of the results from the backpropagation,\n",
    "    layer by layer.\n",
    "    \"\"\"\n",
    "    Y_hat = results[-1][\"post_activation\"]\n",
    "    \n",
    "    G = results[-1][\"post_activation\"]\n",
    "    Fbar = results[-1][\"pre_multi\"]\n",
    "    F = results[0][\"post_activation\"]\n",
    "    Xbar = results[0][\"pre_multi\"]\n",
    "    W = params[-1][1:]\n",
    "    \n",
    "    # This first version doesn't use a loop and therefore is not capable of handling\n",
    "    # networks of different sizes\n",
    "    dE_dW = np.transpose(Fbar) @ ((G - Y) * G * (1-G))\n",
    "    dE_dW /= Y_hat.shape[0]\n",
    "    \n",
    "    dE_dV = (G - Y) * G * (1-G)\n",
    "    dE_dV = dE_dV @ np.transpose(W)\n",
    "    dE_dV = dE_dV * F * (1 - F)\n",
    "    dE_dV = np.transpose(Xbar) @ dE_dV\n",
    "    dE_dV /= Y_hat.shape[0]\n",
    "    \n",
    "    # We update the parameters\n",
    "    params[0] -= learning_rate * dE_dV\n",
    "    params[1] -= learning_rate * dE_dW\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la fonction avec un Y de 4\n",
    "new_params = back_propagate(params, results, revert_argmax(4), learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the full algorithm\n",
    " Now that all of the important functions are here, we are ready to create our train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, layers, batch_size, stop_threshold=0, n_iterations=30,\\\n",
    "                learning_rate=0.1, verbose=True, test_data=None):\n",
    "    \"\"\"\n",
    "    Train_data is the dataframe we have created\n",
    "    If stop threshold is 0 we run for a set number of iterations.\n",
    "    Else, we run until the progress we make on the error is under a certain number or the number of\n",
    "    iterations is reached, whichever comes first\n",
    "    \"\"\"\n",
    "    # First, we initialise the parameters\n",
    "    params = initialize_parameters(layers)\n",
    "    \n",
    "    # Then we split the training data between X and Y\n",
    "    X = train_data.drop([\"Label\"], axis=1).values\n",
    "    Y = revert_argmax_vectorized(train_data[\"Label\"].values)\n",
    "    \n",
    "    # We loop through the iterations\n",
    "    itera = 0\n",
    "    stop = False\n",
    "    SSE_list = []\n",
    "    while not stop:\n",
    "        # This is where we split the training data into batches\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch = X[i:i+batch_size, :]\n",
    "            Y_batch = Y[i:i+batch_size, :]\n",
    "        \n",
    "            # We feed the data to the model\n",
    "            results = feed_forward_batch(X_batch, params)\n",
    "\n",
    "            # We measure the SSE\n",
    "            SSE = compute_SSE(results[-1][\"post_activation\"], Y_batch)\n",
    "\n",
    "            # Actual training\n",
    "            params = back_propagate(params, results, Y_batch, learning_rate)\n",
    "            \n",
    "        # We store our SSE so we can make graphs later\n",
    "        SSE_list.append(SSE)\n",
    "        if verbose and itera%10 == 0:\n",
    "            print(\"Iteration : \", itera, \"\\tSSE = \", SSE)\n",
    "            test_model(test_data, params)\n",
    "        \n",
    "        itera += 1\n",
    "        if n_iterations != None:\n",
    "            if itera >= n_iterations:\n",
    "                stop = True\n",
    "        if len(SSE_list) > 1:\n",
    "            if np.abs(SSE_list[-1] - SSE_list[-2]) < stop_threshold:\n",
    "                stop = True\n",
    "                \n",
    "    return params, SSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0 \tSSE =  8.890441828154064\n",
      "Accuracy :  33.300000000000004 %\n",
      "Iteration :  10 \tSSE =  2.339040152140559\n",
      "Accuracy :  86.6 %\n",
      "Iteration :  20 \tSSE =  1.373626856370678\n",
      "Accuracy :  90.60000000000001 %\n",
      "Iteration :  30 \tSSE =  0.9908159451409607\n",
      "Accuracy :  91.8 %\n",
      "Iteration :  40 \tSSE =  0.7552060172639183\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  50 \tSSE =  0.5862720218639379\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  60 \tSSE =  0.45780279958584613\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  70 \tSSE =  0.3607632990738938\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  80 \tSSE =  0.28887864255212997\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  90 \tSSE =  0.23567139090178832\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  100 \tSSE =  0.19567306001130402\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  110 \tSSE =  0.16507201690735046\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  120 \tSSE =  0.14133422560313422\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  130 \tSSE =  0.12273102083043887\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  140 \tSSE =  0.1080505621659409\n",
      "Accuracy :  94.0 %\n",
      "Iteration :  150 \tSSE =  0.09641890579446984\n",
      "Accuracy :  94.1 %\n",
      "Iteration :  160 \tSSE =  0.08717288835140495\n",
      "Accuracy :  94.19999999999999 %\n",
      "Iteration :  170 \tSSE =  0.0797962385506748\n",
      "Accuracy :  94.19999999999999 %\n",
      "Iteration :  180 \tSSE =  0.07389247617666446\n",
      "Accuracy :  94.3 %\n",
      "Iteration :  190 \tSSE =  0.06915444446303191\n",
      "Accuracy :  94.39999999999999 %\n",
      "Iteration :  200 \tSSE =  0.0653389013331851\n",
      "Accuracy :  94.5 %\n",
      "Iteration :  210 \tSSE =  0.06225223708997473\n",
      "Accuracy :  94.6 %\n",
      "Iteration :  220 \tSSE =  0.059730349609455974\n",
      "Accuracy :  94.6 %\n",
      "Iteration :  230 \tSSE =  0.05761012164521862\n",
      "Accuracy :  94.69999999999999 %\n",
      "Iteration :  240 \tSSE =  0.055722248399973924\n",
      "Accuracy :  94.6 %\n",
      "Iteration :  250 \tSSE =  0.05392754076623669\n",
      "Accuracy :  94.69999999999999 %\n",
      "Iteration :  260 \tSSE =  0.0521703648335509\n",
      "Accuracy :  94.69999999999999 %\n",
      "Iteration :  270 \tSSE =  0.05048395307140183\n",
      "Accuracy :  94.8 %\n",
      "Iteration :  280 \tSSE =  0.04893075610740325\n",
      "Accuracy :  94.8 %\n",
      "Iteration :  290 \tSSE =  0.047553583423097984\n",
      "Accuracy :  94.69999999999999 %\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_train_test(data_set, 0.8)\n",
    "\n",
    "model, SSE_list = train_model(train_data, [50, 10], 10, stop_threshold=0, n_iterations=300,\\\n",
    "                learning_rate=0.1, verbose=True, test_data=test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Accuracy :  97.82499999999999 %\n",
      "test\n",
      "Accuracy :  94.6 %\n"
     ]
    }
   ],
   "source": [
    "# We test our model\n",
    "print(\"train\")\n",
    "train_acc = test_model(train_data, model)\n",
    "print(\"test\")\n",
    "test_results = test_model(test_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 50)\n",
      "(51, 10)\n"
     ]
    }
   ],
   "source": [
    "for param in model:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test recognizing a picture\n",
    "* Now that our model is  trained, we can try it with different pictures to see what our model is capable of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_result(model, X):\n",
    "    \"\"\"\n",
    "    X is an image of size 400 that we can feed to our model\n",
    "    \"\"\"\n",
    "    X = np.reshape(X, (1, 400))\n",
    "    result = feed_forward_batch(X, model)\n",
    "    Y_hat = result[-1][\"post_activation\"]\n",
    "    \n",
    "    predicted = np.argmax(Y_hat, axis=1)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would also like to have a function to see what these numbers look like\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_number(X):\n",
    "    \"\"\"\n",
    "    X should be of size 400, Y should be a number.\n",
    "    \"\"\"\n",
    "    pixels = X.reshape((20, 20))\n",
    "    pixels = np.transpose(pixels)\n",
    "\n",
    "    plt.imshow(pixels, cmap='gray_r',origin='upper')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEYFJREFUeJzt3X2MVXV+x/HPhwGf0FQUQUTYNSti6KbQFbEuaQO1KhqzaLPbYmqLrQ2WLEnVmtTWjRr7z7L1KRYjcQUfml2fWtklWVYZtYmr7oNI8KlCReLqCIGOrrpGRxz49o85mOlwfvK799yZ+8D7lZB77jnfOed3Z+DDOff+5nwdEQKAMqOaPQAArYuAAJBEQABIIiAAJBEQAJIICABJBASAJAICQBIBASBpdLMHUGb8+PExderUZg8D6FhvvfWWent7faC6lgyIqVOn6tlnn232MICONXfu3Ky6SpcYthfY3mJ7q+1rSrYfavuhYvsvbX+5yvEAjKy6A8J2l6Q7JJ0naYaki23PGFJ2maTfRMTJkm6VtLze4wEYeVXOIOZI2hoR2yJit6QHJS0cUrNQ0n3F8n9IOsv2Aa97ALSGKgExWdLbg573FOtKayKiX9IHko6tcEwAI6hKQJSdCQy9uUROzUChvcT2Btsbent7KwwLQKNUCYgeSVMGPT9R0vZUje3Rkn5H0ntlO4uIuyJidkTMHj9+fIVhAWiUKgHxvKRptk+yfYikRZLWDqlZK2lxsfxNSU8Ft7AC2kbd8yAiot/2MkmPS+qStDoiXrV9o6QNEbFW0ipJ/257qwbOHBY1YtAARkaliVIRsU7SuiHrrhu03CfpW1WOAaB5+F0MAEkEBIAkAgJAEgEBIImAAJBEQABIIiAAJBEQAJIICABJBASAJAICQFJL3rQWaBW1/PLxmDFjsmu7urqyaz/99NPs2kbjDAJAEgEBIImAAJBEQABIIiAAJBEQAJKqdNaaYvu/bL9m+1Xbf19SM8/2B7Y3FX+uK9sXgNZUZR5Ev6R/iIiNto+S9ILt7oj47yF1P4uICyocB0CT1H0GERE7ImJjsfxbSa9p/85aANpYQ96DKLp2/76kX5ZsPtP2i7Z/avt3G3E8ACOj8lRr20dK+k9JV0TEh0M2b5T0pYj4yPb5kn4kaVpiP0skLZGkKVOmlJVghA1Xn+V26p1Uy/TpN954I7t2x44d2bVnnnlmdm2jv7eVziBsj9FAOPwgIh4duj0iPoyIj4rldZLG2C7tq0frPaD1VPkUwxronPVaRNySqDm+qJPtOcXx3q33mABGVpVLjLmS/lLSy7Y3Fev+WdJUSYqIlRrox7nUdr+kTyQtojcn0D6q9OZ8RtIXXqRGxApJK+o9BoDmYiYlgCQCAkASAQEgiYAAkERAAEgiIAAkcVfrg0wtd1P++OOPs2trmd5y2GGHZdcOl1Gj8v5vrOV78L3vfS+7dtu2bdm13d3d2bX9/f3ZtTk4gwCQREAASCIgACQREACSCAgASQQEgCQCAkASAQEgiYAAkMRMyg4wenT+j3HLli3ZtVdeeWV27amnnppde/vtt2fX9vX1ZdfWIndG6f3335+9z0cf3e+2rEkrVuTfR2m4bh6cgzMIAEmVA8L2m7ZfLlrrbSjZbtu3295q+yXbX6t6TAAjo1GXGPMjojex7TwN9MKYJukMSXcWjwBa3EhcYiyUdH8M+IWko21PGoHjAqioEQERktbbfqHojjXUZElvD3reI3p4Am2hEZcYcyNiu+0Jkrptb46IpwdtL3sLdr+bB9B6D2g9lc8gImJ78bhL0hpJc4aU9Ega/C/+REnbS/ZD6z2gxVTtzTnW9lH7liWdI+mVIWVrJf1V8WnGH0j6ICLyO5cCaJqqlxgTJa0pJnKMlvTDiHjM9t9Jn7ffWyfpfElbJX0s6a8rHhPACKkUEBGxTdLMkvUrBy2HpG9XOQ6A5mCqdYuqZfr0zp07s2uvuuqq7Nonnngiu3b69OnZtcOllu/Z5s2bs+qWL1+evc+vf/3r2bULFizIrt2zZ092baMx1RpAEgEBIImAAJBEQABIIiAAJBEQAJIICABJBASAJAICQBIBASCJqdYjaNSo/Dzeu3dvdu21116bXVvL9OlLL700u/Y73/lOdu2nn36aXZt792lJevfdd7Nrr7766oYfv5bvwbhx47Jrd+/enV3baJxBAEgiIAAkERAAkggIAEkEBIAkAgJAEgEBIKnugLA9vejHue/Ph7avGFIzz/YHg2quqz5kACOl7olSEbFF0ixJst0l6R0N9MUY6mcRcUG9xwHQPI26xDhL0hsR8esG7Q9AC2jUVOtFkh5IbDvT9osa6KZ1dUS8WlbUzq33ir4gB1TL9OlVq1Zl1z7yyCPZtfPmzcuuveGGG7JrjzvuuOzaWqYO1zI9/eGHH86ufeqpp7Lqli5dmr3P008/Pbv2s88+y65tpspnELYPkfQNSWV/SzdK+lJEzJT0b5J+lNoPrfeA1tOIS4zzJG2MiP2aM0TEhxHxUbG8TtIY2/zrB9pEIwLiYiUuL2wf7+L82/ac4nj5v3IHoKkqvQdh+whJZ0u6fNC6wX05vylpqe1+SZ9IWlS04gPQBqr25vxY0rFD1g3uy7lC0ooqxwDQPMykBJBEQABIIiAAJBEQAJIICABJ3NW6AcaMGZNV193dnb3P5cuXZ9dOnDgxu/bGG2/Mrp08eXJ2bS0OP/zw7NqtW7dm195zzz3ZtaecckpW3bJly7L3Wcsn+O3yaT9nEACSCAgASQQEgCQCAkASAQEgiYAAkERAAEgiIAAkERAAkggIAElMtU7InT4tSVu2bMmqu+66/L5Bu3btyq6dMWNGdu369euza9esKWtzUm7mzJnZtbNnz86uveuuu7JrN23alF179913Z9WdfPLJ2fvs6+vLrm0XnEEASMoKCNurbe+y/cqgdcfY7rb9evE4LvG1i4ua120vbtTAAQy/3DOIeyUtGLLuGklPRsQ0SU8Wz/8f28dIul7SGZLmSLo+FSQAWk9WQETE05LeG7J6oaT7iuX7JF1Y8qXnSuqOiPci4jeSurV/0ABoUVXeg5gYETskqXicUFIzWdLbg573FOsAtIHhfpOyrGll6Z0ybC+xvcH2ht7e3mEeFoAcVQJip+1JklQ8ln0u1yNpcCfeEzXQxHc/9OYEWk+VgFgrad+nEosl/bik5nFJ59geV7w5eU6xDkAbyP2Y8wFJP5c03XaP7cskfVfS2bZf10D7ve8WtbNt3y1JEfGepH+R9Hzx58ZiHYA2kDWTMiIuTmw6q6R2g6S/HfR8taTVdY0OQFMdVFOtR43Kv6KqZapz7h2oa5kK3NXVlV372muvZde+88472bVjx47Nrl21alV27aRJk7Jr3303vxl87p2qJem0007LqtuzZ0/2PjsRU60BJBEQAJIICABJBASAJAICQBIBASCJgACQREAASCIgACQREACSDqqp1oceemh27TPPPJNd++CDD2bV1TIV+JJLLsmunT9/fnbt0UcfnV175JFHZtdu3Lgxu3bp0qXZtbW46aabsmtPPfXUrLrPPvus3uF0BM4gACQREACSCAgASQQEgCQCAkASAQEg6YABkWi796+2N9t+yfYa26Wfndl+0/bLtjfZ3tDIgQMYfjlnEPdq/25Y3ZK+GhG/J+l/JP3TF3z9/IiYFRH5LZ0BtIQDBkRZ272IWB8R/cXTX2ig3wWADtOI9yD+RtJPE9tC0nrbL9he0oBjARhBlaZa275WUr+kHyRK5kbEdtsTJHXb3lyckZTta4mkJZI0ZcqUspLKarlD8YQJZa1Gy1100UVZdVdccUX2Ps8444zs2uG687Jd1jmxXC1Trd9///3s2quuuiq79txzz82u3bt3b3btwazuMwjbiyVdIOkvIqK032ZEbC8ed0laI2lOan+03gNaT10BYXuBpH+U9I2I+DhRM9b2UfuWNdB275WyWgCtKedjzrK2eyskHaWBy4ZNtlcWtSfYXld86URJz9h+UdKvJP0kIh4bllcBYFgc8D2IRNu90jZKxSXF+cXyNkkzK40OQFMxkxJAEgEBIImAAJBEQABIIiAAJBEQAJIOqrta7969O7t29uz8Xz5duXJlVt0RRxyRvc++vr7s2lqMGTMmu/a5557Lrr3tttuya2uZRr5s2bLs2lokJv9iCM4gACQREACSCAgASQQEgCQCAkASAQEgiYAAkERAAEgiIAAkHVQzKWsxenT+tyZ3duJw3Vy2q6sru3bnzp3Ztbfcckt27ahR+f/X1DI78thjj82urWWmLPJwBgEgqd7WezfYfqe4H+Um2+cnvnaB7S22t9q+ppEDBzD86m29J0m3Fi31ZkXEuqEbbXdJukPSeZJmSLrY9owqgwUwsupqvZdpjqStEbEtInZLelDSwjr2A6BJqrwHsazo7r3a9riS7ZMlvT3oeU+xDkCbqDcg7pT0FUmzJO2QdHNJTVnftuQv4dteYnuD7Q29vb11DgtAI9UVEBGxMyL2RMReSd9XeUu9HkmDm2yeKGn7F+yT1ntAi6m39d6kQU8vUnlLveclTbN9ku1DJC2StLae4wFojgPOBipa782TNN52j6TrJc2zPUsDlwxvSrq8qD1B0t0RcX5E9NteJulxSV2SVkfEq8PyKgAMi2FrvVc8Xydpv49AAbQHplon1HJT03a6AWp/f3927YUXXphde9lll2XXnn322dm1TJ9uLqZaA0giIAAkERAAkggIAEkEBIAkAgJAEgEBIImAAJBEQABIIiAAJDHVugPUcrfs448/Prt28eLF2bW1TDfv6+vLrkVzcQYBIImAAJBEQABIIiAAJBEQAJIICABJOfekXC3pAkm7IuKrxbqHJE0vSo6W9H5EzCr52jcl/VbSHkn9ETG7QeMGMAJy5kHcK2mFpPv3rYiIP9+3bPtmSR98wdfPjwgaXQBtKOemtU/b/nLZNtuW9GeS/rixwwLQCqq+B/GHknZGxOuJ7SFpve0XbC+peCwAI6zqVOuLJT3wBdvnRsR22xMkddveXDQD3k8RIEskacqUKWUlaIC9e/dm137yySfDOBK0g7rPIGyPlvSnkh5K1RR9MhQRuyStUXmLvn21tN4DWkyVS4w/kbQ5InrKNtoea/uofcuSzlF5iz4ALeqAAVG03vu5pOm2e2zv65CySEMuL2yfYHtfJ62Jkp6x/aKkX0n6SUQ81rihAxhu9bbeU0RcWrLu89Z7EbFN0syK4wPQRMykBJBEQABIIiAAJBEQAJIICABJBASAJAICQBIBASCJgACQREAASCIgACQREACSCAgASQQEgCQCAkASAQEgiYAAkOSIaPYY9mP7fyX9esjq8ZI6sQFPp74uqXNfWye8ri9FxHEHKmrJgChje0Mntu7r1Nclde5r69TXVYZLDABJBASApHYKiLuaPYBh0qmvS+rc19apr2s/bfMeBICR105nEABGWFsEhO0FtrfY3mr7mmaPp1Fsv2n7ZdubbG9o9niqsL3a9i7brwxad4ztbtuvF4/jmjnGeiRe1w223yl+bptsn9/MMQ6nlg8I212S7pB0nqQZki62PaO5o2qo+RExqwM+NrtX0oIh666R9GRETJP0ZPG83dyr/V+XJN1a/NxmRcS6ku0doeUDQgMdwbdGxLaI2C3pQUkLmzwmDBERT0t6b8jqhZLuK5bvk3ThiA6qARKv66DRDgExWdLbg573FOs6QUhab/sF20uaPZhhMDEidkhS8TihyeNppGW2XyouQdru0ilXOwSES9Z1ykcvcyPiaxq4fPq27T9q9oCQ5U5JX5E0S9IOSTc3dzjDpx0CokfSlEHPT5S0vUljaaiiG7oiYpekNRq4nOokO21PkqTicVeTx9MQEbEzIvZExF5J31fn/dw+1w4B8bykabZPsn2IpEWS1jZ5TJXZHmv7qH3Lks6R9MoXf1XbWStpcbG8WNKPmziWhtkXeoWL1Hk/t8+NbvYADiQi+m0vk/S4pC5JqyPi1SYPqxEmSlpjWxr4OfwwIh5r7pDqZ/sBSfMkjbfdI+l6Sd+V9LDtyyS9JelbzRthfRKva57tWRq41H1T0uVNG+AwYyYlgKR2uMQA0CQEBIAkAgJAEgEBIImAAJBEQABIIiAAJBEQAJL+D7y95MlTNbViAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  5\n"
     ]
    }
   ],
   "source": [
    "X = data_set.loc[2100].drop([\"Label\"]).values\n",
    "draw_number(X)\n",
    "print(\"Prediction : \", get_one_result(model, X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results\n",
    "\n",
    "Now that we have trained our model, we want to figure out what it doesn't do well.\n",
    "We start by isolating all the numbers on which we failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 770 entries, 0 to 999\n",
      "Columns: 401 entries, Label to Pixel_99\n",
      "dtypes: float64(401)\n",
      "memory usage: 2.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get the results of the test\n",
    "test_outputs = test_results[-1][\"post_activation\"]\n",
    "number_predicted = np.argmax(test_outputs, axis=1)\n",
    "\n",
    "# Error will contain all the images that were mispredicted\n",
    "errors = pd.DataFrame()\n",
    "for i, predicted in enumerate(number_predicted):\n",
    "    if test_data.loc[i]['Label'] != predicted:\n",
    "        errors = errors.append(test_data.loc[i])\n",
    "        \n",
    "print(errors.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected : 2.0\n",
      "Prediction : 6\n"
     ]
    }
   ],
   "source": [
    "check = 0\n",
    "X = errors.iloc[check].drop([\"Label\"]).values\n",
    "draw_number(X)\n",
    "print(\"Expected :\", errors.iloc[check][\"Label\"])\n",
    "print(\"Prediction :\", get_one_result(model, X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random number "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
