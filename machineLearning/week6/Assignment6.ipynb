{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6 : Hand written digits recognition\n",
    "\n",
    "## First step : loading and processing the data\n",
    "Load the images into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 400 entries, Pixel_0 to Pixel_399\n",
      "dtypes: float64(395), int64(5)\n",
      "memory usage: 15.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>Pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_390</th>\n",
       "      <th>Pixel_391</th>\n",
       "      <th>Pixel_392</th>\n",
       "      <th>Pixel_393</th>\n",
       "      <th>Pixel_394</th>\n",
       "      <th>Pixel_395</th>\n",
       "      <th>Pixel_396</th>\n",
       "      <th>Pixel_397</th>\n",
       "      <th>Pixel_398</th>\n",
       "      <th>Pixel_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pixel_0  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  Pixel_7  \\\n",
       "0        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Pixel_8  Pixel_9    ...      Pixel_390  Pixel_391  Pixel_392  Pixel_393  \\\n",
       "0      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "1      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "2      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "3      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "4      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Pixel_394  Pixel_395  Pixel_396  Pixel_397  Pixel_398  Pixel_399  \n",
       "0        0.0        0.0        0.0        0.0        0.0          0  \n",
       "1        0.0        0.0        0.0        0.0        0.0          0  \n",
       "2        0.0        0.0        0.0        0.0        0.0          0  \n",
       "3        0.0        0.0        0.0        0.0        0.0          0  \n",
       "4        0.0        0.0        0.0        0.0        0.0          0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of a dataframe to hold the images\n",
    "data_set = pd.read_csv(\"image_0.txt\", header=None, names=\\\n",
    "                      [\"Pixel_\"+str(x) for x in range(400)])\n",
    "print(data_set.info())\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the labels to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 401 entries, Label to Pixel_399\n",
      "dtypes: float64(395), int64(6)\n",
      "memory usage: 15.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_390</th>\n",
       "      <th>Pixel_391</th>\n",
       "      <th>Pixel_392</th>\n",
       "      <th>Pixel_393</th>\n",
       "      <th>Pixel_394</th>\n",
       "      <th>Pixel_395</th>\n",
       "      <th>Pixel_396</th>\n",
       "      <th>Pixel_397</th>\n",
       "      <th>Pixel_398</th>\n",
       "      <th>Pixel_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Pixel_0  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  \\\n",
       "0      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Pixel_7  Pixel_8    ...      Pixel_390  Pixel_391  Pixel_392  Pixel_393  \\\n",
       "0      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "1      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "2      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "3      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "4      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Pixel_394  Pixel_395  Pixel_396  Pixel_397  Pixel_398  Pixel_399  \n",
       "0        0.0        0.0        0.0        0.0        0.0          0  \n",
       "1        0.0        0.0        0.0        0.0        0.0          0  \n",
       "2        0.0        0.0        0.0        0.0        0.0          0  \n",
       "3        0.0        0.0        0.0        0.0        0.0          0  \n",
       "4        0.0        0.0        0.0        0.0        0.0          0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[\"Label\"] = pd.read_csv(\"label.txt\", header=None, names=[\"Label\"])\n",
    "# Replace the 10s with actual zeros\n",
    "def ten_to_zero(x):\n",
    "    if x == 10:\n",
    "        return 0\n",
    "    return x\n",
    "data_set[\"Label\"] = data_set[\"Label\"].apply(func=ten_to_zero)\n",
    "# Reorganize the columns so that Label is first on the list\n",
    "cols = data_set.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "data_set = data_set[cols]\n",
    "\n",
    "print(data_set.info())\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, proportion=0.8):\n",
    "    shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_data = shuffled_data[:int(0.8 * shuffled_data.shape[0])]\\\n",
    "            .reset_index(drop=True)\n",
    "    test_data = shuffled_data[int(0.8 * shuffled_data.shape[0]):]\\\n",
    "            .reset_index(drop=True)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Columns: 401 entries, Label to Pixel_399\n",
      "dtypes: float64(395), int64(6)\n",
      "memory usage: 12.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test the split function\n",
    "train_data, test_data = split_train_test(data_set)\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we define the parameters of our model\n",
    "* We define a function to initialize parameteres randomly\n",
    "* Each layer of neurons should have a parameter matrix of shape (m, n) where m is the size of the output of the previous layer (or the size of the input in the case of the first layer) + 1, to add the intercept, and n is the number of neurons in this layer.\n",
    "\n",
    "### Example\n",
    "For instance if we have a network with 400 inputs, 25 neurons in the first layer and 10 in the second, we should have parameters like so : \n",
    "* First layer : (401, 25)\n",
    "* Second layer : (26, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layers, n_inputs=400):\n",
    "    \"\"\"\n",
    "        layers is a list. Each of its item represents one layer, and \n",
    "    the number it contains is the size of that layer. The last layer\n",
    "    should always have the size of the expected output (in our case 10)\n",
    "        Our model will then apply argmax to these 10 numbers to find out \n",
    "    which digit was detected.\n",
    "    \n",
    "        The return value is a dic containing a numpy array for each set\n",
    "    of parameters\n",
    "    \"\"\"\n",
    "    parameters = []\n",
    "    \n",
    "    slices = [n_inputs] + layers\n",
    "    \n",
    "    # We loop throught the number of layers to generate parameters\n",
    "    # matrix of the appropriate size\n",
    "    for i, layer in enumerate(layers):\n",
    "        \n",
    "        parameters.append(\\\n",
    "        np.random.randn((slices[i]+1), slices[i+1]))\n",
    "        parameters[i] = parameters[i] * 0.01\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 25)\n",
      "(26, 10)\n",
      "-0.0003896003914156016\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "layers = [25, 10]\n",
    "params = initialize_parameters(layers)\n",
    "for row in params:\n",
    "    print(row.shape)\n",
    "    \n",
    "print(params[0][0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the feed forward function\n",
    "This step is just a couple of matrix multiplication, which are easy to implement and run very fast thanks to numpy.\n",
    "\n",
    "To make it work, we must first define the sigmoid function that we will\n",
    "be using for activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.power(1 + np.exp(-x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_batch(batch, params):\n",
    "    \"\"\"\n",
    "        Given a batch of inputs, this function will return an equivalent\n",
    "    batch of outputs. The intermediate values are also returned so they\n",
    "    can be cached for back propagation.\n",
    "    \n",
    "    * Inputs : batch must be a numpy array of shape m * 400 where m\n",
    "    represents the batch size, and 400 is the size of the images\n",
    "    \n",
    "    * Outputs : All of the intermediate and final values of our feed_forward\n",
    "    are contained in results. It is a list of dics.\n",
    "    Each dic contains two entries, Xbarbar which is the sum before the \n",
    "    sigmoid activation function, and F which does contain the activation\n",
    "    function\n",
    "    \"\"\"\n",
    "    # X is the matrix of values taht we will feed to the neural\n",
    "    # network\n",
    "    X = np.copy(batch)\n",
    "    image_size = X.shape[0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    for i, param_matrix in enumerate(params):\n",
    "        results_dic = {}\n",
    "        # We pad the batch with a row of ones to create an intercept\n",
    "        Xbar = np.concatenate((np.ones([X.shape[0], 1]), X), axis=1)\n",
    "        # We store the results from before the multiplication with \n",
    "        # the params for the need of the backpropagation\n",
    "        results_dic[\"pre_multi\"] = Xbar\n",
    "        # Then we multiply the padded batch of vectors with the params\n",
    "        Xbarbar = np.dot(Xbar, param_matrix)\n",
    "        # We cache the results for faster backprop\n",
    "        results_dic[\"pre_activation\"] = Xbarbar\n",
    "        # Then we need to apply the activation function to the product\n",
    "        F = sigmoid(Xbarbar)\n",
    "        # We also store the results from after this operation because\n",
    "        # at this point why not\n",
    "        results_dic[\"post_activation\"] = F\n",
    "        # Finally we put F into X to allow for the next step of the loop\n",
    "        X = F\n",
    "        \n",
    "        results.append(results_dic)\n",
    "        \n",
    "    # Once this loop is completed, we should have our output ready\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 400)\n",
      "(4000, 10)\n",
      "[0 0 0 ... 0 0 0]\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "# Test of the feed_forward function\n",
    "print(train_data.drop([\"Label\"], axis=1).values.shape)\n",
    "X = train_data.drop([\"Label\"], axis=1).values\n",
    "Y = train_data[\"Label\"].values\n",
    "results = feed_forward_batch(X, params)\n",
    "Y_hat = results[-1][\"post_activation\"]\n",
    "print(Y_hat.shape)\n",
    "print(np.argmax(Y_hat, axis=1))\n",
    "print(np.argmax(Y_hat, axis=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the back propagation\n",
    "We are now able to run our model to predict a result. We now need to implement the back propagation algorith to modify the parameters in the direction of the right result.\n",
    "\n",
    "* Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_argmax(x):\n",
    "    \"\"\"\n",
    "    First let's make a function to convert a number between 0 and 9\n",
    "    to a vector of numbers between 0 and 1\n",
    "    \"\"\"\n",
    "    return_value = np.zeros((10))\n",
    "    return_value[x] = 1\n",
    "    return return_value\n",
    "\n",
    "def revert_argmax_vectorized(x):\n",
    "    \"\"\"\n",
    "    x is a numpy vector\n",
    "    \"\"\"\n",
    "    return_value = np.zeros((x.shape[0], 10))\n",
    "    \n",
    "    for i, value in enumerate(x):\n",
    "        return_value[i, value] = 1\n",
    "    \n",
    "    return return_value\n",
    "\n",
    "def compute_SSE(Y_hat, Y):\n",
    "    SE = np.power(Y_hat - Y, 2)\n",
    "    SSE = np.sum(SE)\n",
    "    return SSE\n",
    "\n",
    "def compute_cost(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Y_hat and Y must be (m, 10) dimensional matrices or vectors\n",
    "    \"\"\"\n",
    "    assert Y_hat.shape[1] == 10\n",
    "    cost = Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat)\n",
    "    return np.sum(cost) / Y_hat.shape[0]\n",
    "\n",
    "def accuracy_eval(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Y_hat and Y must be matrices of shape (m, 10) where me is the number of examples\n",
    "    \"\"\"\n",
    "    got_it = 0\n",
    "    for i in range(Y_hat.shape[0]):\n",
    "        if np.argmax(Y_hat[i]) == Y[i]:\n",
    "            got_it += 1\n",
    "            \n",
    "    accuracy = got_it / Y_hat.shape[0]\n",
    "    \n",
    "    return accuracy, got_it\n",
    "\n",
    "def test_model(test_data, model):\n",
    "    X_test = test_data.drop([\"Label\"], axis=1).values\n",
    "    Y_test = test_data[\"Label\"].values\n",
    "\n",
    "    test_results = feed_forward_batch(X_test, model)\n",
    "    \n",
    "    accuracy, _ = accuracy_eval(test_results[-1][\"post_activation\"], Y_test)\n",
    "    print(\"Accuracy : \", accuracy * 100, \"%\")\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Actual back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This part was only for tests nut now I am afraid to delete it please ignore\n",
    "\"\"\"\n",
    "\n",
    "def one_layer_back_propagate(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    * Params must be a numpy matrix containing the parameters for\n",
    "    one layer.\n",
    "    * Results contains the result of a layer\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def back_propagate_custom(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    This function will run backwards through the neural net, computing \n",
    "    the derivatives to modify the parameters according to the learning\n",
    "    rate.\n",
    "    \n",
    "    * Y should be a (batch_size, 10) matrix.\n",
    "    * results contains all of the results from the backpropagation,\n",
    "    layer by layer.\n",
    "    \"\"\"\n",
    "    Y_hat = results[-1][\"post_activation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    ========= IMPORTANT ===========\n",
    "    This version of the function is not generealisable to different\n",
    "    number of layers.\n",
    "    \n",
    "    This function will run backwards through the neural net, computing \n",
    "    the derivatives to modify the parameters according to the learning\n",
    "    rate.\n",
    "    \n",
    "    * Y should be a (batch_size, 10) matrix.\n",
    "    * results contains all of the results from the backpropagation,\n",
    "    layer by layer.\n",
    "    \"\"\"\n",
    "    Y_hat = results[-1][\"post_activation\"]\n",
    "    \n",
    "    G = results[-1][\"post_activation\"]\n",
    "    Fbar = results[-1][\"pre_multi\"]\n",
    "    F = results[0][\"post_activation\"]\n",
    "    Xbar = results[0][\"pre_multi\"]\n",
    "    W = params[-1][1:]\n",
    "    \n",
    "    # This first version doesn't use a loop and therefore is not capable of handling\n",
    "    # networks of different sizes\n",
    "    dE_dW = np.transpose(Fbar) @ (G - Y) # * G * (1-G)\n",
    "    dE_dW /= Y_hat.shape[0]\n",
    "    \n",
    "    dE_dV = (G - Y) # * G * (1-G)\n",
    "    dE_dV = dE_dV @ np.transpose(W)\n",
    "    dE_dV = dE_dV * F * (1 - F)\n",
    "    dE_dV = np.transpose(Xbar) @ dE_dV\n",
    "    dE_dV /= Y_hat.shape[0]\n",
    "    \n",
    "    # We update the parameters\n",
    "    params[0] -= learning_rate * dE_dV\n",
    "    params[1] -= learning_rate * dE_dW\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la fonction avec un Y de 4\n",
    "new_params = back_propagate(params, results, revert_argmax(4), learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the full algorithm\n",
    " Now that all of the important functions are here, we are ready to create our train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, layers=[25, 10], stop_threshold=0, n_iterations=30,\\\n",
    "                learning_rate=0.1, verbose=True, test_data=None):\n",
    "    \"\"\"\n",
    "    Train_data is the dataframe we have created\n",
    "    If stop threshold is 0 we run for a set number of iterations.\n",
    "    Else, we run until the progress we make on the error is under a certain number or the number of\n",
    "    iterations is reached, whichever comes first\n",
    "    \"\"\"\n",
    "    # First, we initialise the parameters\n",
    "    params = initialize_parameters(layers)\n",
    "    \n",
    "    # Then we split the training data between X and Y\n",
    "    X = train_data.drop([\"Label\"], axis=1).values\n",
    "    Y = revert_argmax_vectorized(train_data[\"Label\"].values)\n",
    "    \n",
    "    # We loop through the iterations\n",
    "    itera = 0\n",
    "    stop = False\n",
    "    SSE_list = []\n",
    "    while not stop:\n",
    "        # We feed the data to the model\n",
    "        results = feed_forward_batch(X, params)\n",
    "        \n",
    "        # We measure the SSE\n",
    "        SSE = compute_SSE(results[-1][\"post_activation\"], Y)\n",
    "        \n",
    "        # We store our SSE so we can make graphs later\n",
    "        SSE_list.append(SSE)\n",
    "        if verbose and itera%10 == 0:\n",
    "            print(\"Iteration : \", itera, \"\\tSSE = \", SSE)\n",
    "            test_model(test_data, params)\n",
    "        \n",
    "        \"\"\"print(\"F bar\", results[-1][\"pre_multi\"][0, :])\n",
    "        print(\"Parameters last layer : \", params[1][0, :])\n",
    "        print(\"Output : \", results[-1][\"post_activation\"][0, :])\"\"\"\n",
    "        params = back_propagate(params, results, Y, learning_rate)\n",
    "        \n",
    "        itera += 1\n",
    "        if n_iterations != None:\n",
    "            if itera >= n_iterations:\n",
    "                stop = True\n",
    "        if len(SSE_list) > 1:\n",
    "            if np.abs(SSE_list[-1] - SSE_list[-2]) < stop_threshold:\n",
    "                stop = True\n",
    "                \n",
    "    return params, SSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0 \tSSE =  9801.132423683452\n",
      "Accuracy :  9.4 %\n",
      "Iteration :  10 \tSSE =  3626.1277600203343\n",
      "Accuracy :  10.9 %\n",
      "Iteration :  20 \tSSE =  3605.2727374208616\n",
      "Accuracy :  18.2 %\n",
      "Iteration :  30 \tSSE =  3567.0809215187137\n",
      "Accuracy :  38.2 %\n",
      "Iteration :  40 \tSSE =  3438.731661290712\n",
      "Accuracy :  46.0 %\n",
      "Iteration :  50 \tSSE =  3088.885650924048\n",
      "Accuracy :  53.400000000000006 %\n",
      "Iteration :  60 \tSSE =  2649.2303168110793\n",
      "Accuracy :  60.3 %\n",
      "Iteration :  70 \tSSE =  2314.585958577927\n",
      "Accuracy :  67.2 %\n",
      "Iteration :  80 \tSSE =  2067.8860999061976\n",
      "Accuracy :  74.5 %\n",
      "Iteration :  90 \tSSE =  1862.2068453765055\n",
      "Accuracy :  78.2 %\n",
      "Iteration :  100 \tSSE =  1680.5751734035277\n",
      "Accuracy :  81.69999999999999 %\n",
      "Iteration :  110 \tSSE =  1524.4874379621067\n",
      "Accuracy :  83.2 %\n",
      "Iteration :  120 \tSSE =  1394.4899191210416\n",
      "Accuracy :  84.0 %\n",
      "Iteration :  130 \tSSE =  1287.0419312098381\n",
      "Accuracy :  86.1 %\n",
      "Iteration :  140 \tSSE =  1197.3072493145023\n",
      "Accuracy :  86.8 %\n",
      "Iteration :  150 \tSSE =  1121.0890349417068\n",
      "Accuracy :  87.2 %\n",
      "Iteration :  160 \tSSE =  1055.322045330622\n",
      "Accuracy :  88.1 %\n",
      "Iteration :  170 \tSSE =  997.9133884932281\n",
      "Accuracy :  88.4 %\n",
      "Iteration :  180 \tSSE =  947.438685323604\n",
      "Accuracy :  88.8 %\n",
      "Iteration :  190 \tSSE =  902.8784833105701\n",
      "Accuracy :  88.7 %\n",
      "Iteration :  200 \tSSE =  863.4387033304847\n",
      "Accuracy :  89.0 %\n",
      "Iteration :  210 \tSSE =  828.4491397705713\n",
      "Accuracy :  89.2 %\n",
      "Iteration :  220 \tSSE =  797.317300235119\n",
      "Accuracy :  89.7 %\n",
      "Iteration :  230 \tSSE =  769.5133764305644\n",
      "Accuracy :  89.9 %\n",
      "Iteration :  240 \tSSE =  744.5680036914817\n",
      "Accuracy :  90.0 %\n",
      "Iteration :  250 \tSSE =  722.0721809685172\n",
      "Accuracy :  90.2 %\n",
      "Iteration :  260 \tSSE =  701.6750834012435\n",
      "Accuracy :  90.3 %\n",
      "Iteration :  270 \tSSE =  683.0792889355828\n",
      "Accuracy :  90.3 %\n",
      "Iteration :  280 \tSSE =  666.0344257416018\n",
      "Accuracy :  90.5 %\n",
      "Iteration :  290 \tSSE =  650.330380063202\n",
      "Accuracy :  90.60000000000001 %\n",
      "Iteration :  300 \tSSE =  635.7908435903223\n",
      "Accuracy :  90.7 %\n",
      "Iteration :  310 \tSSE =  622.2675897835888\n",
      "Accuracy :  91.2 %\n",
      "Iteration :  320 \tSSE =  609.6355991828607\n",
      "Accuracy :  91.3 %\n",
      "Iteration :  330 \tSSE =  597.7890057175823\n",
      "Accuracy :  91.4 %\n",
      "Iteration :  340 \tSSE =  586.6377704082652\n",
      "Accuracy :  91.5 %\n",
      "Iteration :  350 \tSSE =  576.1049696336821\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  360 \tSSE =  566.1245887089952\n",
      "Accuracy :  91.5 %\n",
      "Iteration :  370 \tSSE =  556.639724556166\n",
      "Accuracy :  91.5 %\n",
      "Iteration :  380 \tSSE =  547.6011169383092\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  390 \tSSE =  538.9659428881903\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  400 \tSSE =  530.6968222804402\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  410 \tSSE =  522.7609935943733\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  420 \tSSE =  515.1296278399143\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  430 \tSSE =  507.77725561272143\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  440 \tSSE =  500.68128761531386\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  450 \tSSE =  493.82161304704334\n",
      "Accuracy :  91.8 %\n",
      "Iteration :  460 \tSSE =  487.1802633212643\n",
      "Accuracy :  91.7 %\n",
      "Iteration :  470 \tSSE =  480.7411308646947\n",
      "Accuracy :  91.8 %\n",
      "Iteration :  480 \tSSE =  474.4897344918678\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  490 \tSSE =  468.41302417503385\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  500 \tSSE =  462.49921904969676\n",
      "Accuracy :  91.8 %\n",
      "Iteration :  510 \tSSE =  456.73767327703735\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  520 \tSSE =  451.11876497519813\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  530 \tSSE =  445.6338038728777\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  540 \tSSE =  440.27495367491474\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  550 \tSSE =  435.03516541292447\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  560 \tSSE =  429.90811834476904\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  570 \tSSE =  424.88816532553994\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  580 \tSSE =  419.97028004893934\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  590 \tSSE =  415.15000417439467\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  600 \tSSE =  410.4233930971849\n",
      "Accuracy :  92.10000000000001 %\n",
      "Iteration :  610 \tSSE =  405.78695993059006\n",
      "Accuracy :  92.10000000000001 %\n",
      "Iteration :  620 \tSSE =  401.23761806235916\n",
      "Accuracy :  92.10000000000001 %\n",
      "Iteration :  630 \tSSE =  396.7726233213922\n",
      "Accuracy :  92.10000000000001 %\n",
      "Iteration :  640 \tSSE =  392.38951725546775\n",
      "Accuracy :  92.10000000000001 %\n",
      "Iteration :  650 \tSSE =  388.0860732234112\n",
      "Accuracy :  92.10000000000001 %\n",
      "Iteration :  660 \tSSE =  383.8602469395783\n",
      "Accuracy :  92.2 %\n",
      "Iteration :  670 \tSSE =  379.71013281619867\n",
      "Accuracy :  92.2 %\n",
      "Iteration :  680 \tSSE =  375.633927004751\n",
      "Accuracy :  92.30000000000001 %\n",
      "Iteration :  690 \tSSE =  371.6298975293635\n",
      "Accuracy :  92.30000000000001 %\n",
      "Iteration :  700 \tSSE =  367.6963614151772\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  710 \tSSE =  363.8316683042523\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  720 \tSSE =  360.03418975591416\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  730 \tSSE =  356.30231325682064\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  740 \tSSE =  352.63443990811527\n",
      "Accuracy :  92.30000000000001 %\n",
      "Iteration :  750 \tSSE =  349.0289847903975\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  760 \tSSE =  345.4843791049069\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  770 \tSSE =  341.99907332530097\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  780 \tSSE =  338.5715407471302\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  790 \tSSE =  335.20028097559236\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  800 \tSSE =  331.8838230356922\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  810 \tSSE =  328.62072791600764\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  820 \tSSE =  325.40959046419096\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  830 \tSSE =  322.24904063725387\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  840 \tSSE =  319.13774417198954\n",
      "Accuracy :  92.5 %\n",
      "Iteration :  850 \tSSE =  316.0744027810337\n",
      "Accuracy :  92.5 %\n",
      "Iteration :  860 \tSSE =  313.0577539996745\n",
      "Accuracy :  92.5 %\n",
      "Iteration :  870 \tSSE =  310.08657081032425\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  880 \tSSE =  307.1596611593751\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  890 \tSSE =  304.27586745939306\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  900 \tSSE =  301.43406614284163\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  910 \tSSE =  298.63316730591697\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  920 \tSSE =  295.8721144559124\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  930 \tSSE =  293.14988435500504\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  940 \tSSE =  290.4654869385324\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  950 \tSSE =  287.81796527680626\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  960 \tSSE =  285.20639554567435\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  970 \tSSE =  282.6298869713748\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  980 \tSSE =  280.08758171855584\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  990 \tSSE =  277.5786546955332\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  1000 \tSSE =  275.10231325697805\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  1010 \tSSE =  272.6577967905399\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  1020 \tSSE =  270.2443761799151\n",
      "Accuracy :  92.80000000000001 %\n",
      "Iteration :  1030 \tSSE =  267.8613531422658\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  1040 \tSSE =  265.50805944253506\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  1050 \tSSE =  263.18385599104596\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  1060 \tSSE =  260.8881318338566\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  1070 \tSSE =  258.6203030477163\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  1080 \tSSE =  256.37981155322564\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1090 \tSSE =  254.1661238610086\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1100 \tSSE =  251.97872976642884\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1110 \tSSE =  249.81714100868595\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1120 \tSSE =  247.68088991005467\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1130 \tSSE =  245.56952801062494\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1140 \tSSE =  243.48262471320106\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1150 \tSSE =  241.4197659520615\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1160 \tSSE =  239.38055289810714\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1170 \tSSE =  237.36460071157097\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1180 \tSSE =  235.37153735197512\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1190 \tSSE =  233.4010024534411\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1200 \tSSE =  231.45264627183178\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1210 \tSSE =  229.5261287085712\n",
      "Accuracy :  93.2 %\n",
      "Iteration :  1220 \tSSE =  227.62111841439383\n",
      "Accuracy :  93.2 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  1230 \tSSE =  225.7372919747483\n",
      "Accuracy :  93.2 %\n",
      "Iteration :  1240 \tSSE =  223.8743331771601\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1250 \tSSE =  222.03193235956124\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  1260 \tSSE =  220.20978583744449\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  1270 \tSSE =  218.40759540670956\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  1280 \tSSE =  216.62506791823537\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1290 \tSSE =  214.86191491955265\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1300 \tSSE =  213.11785235847938\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1310 \tSSE =  211.39260034323354\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1320 \tSSE =  209.6858829533178\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1330 \tSSE =  207.99742809538793\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1340 \tSSE =  206.32696739833727\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1350 \tSSE =  204.67423614195116\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1360 \tSSE =  203.03897321368464\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  1370 \tSSE =  201.42092108838153\n",
      "Accuracy :  93.2 %\n",
      "Iteration :  1380 \tSSE =  199.81982582606798\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1390 \tSSE =  198.23543708330652\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1400 \tSSE =  196.66750813397385\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1410 \tSSE =  195.1157958957192\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1420 \tSSE =  193.58006095875845\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1430 \tSSE =  192.0600676140589\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1440 \tSSE =  190.55558387836146\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1450 \tSSE =  189.06638151386963\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1460 \tSSE =  187.59223604080216\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1470 \tSSE =  186.13292674136025\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1480 \tSSE =  184.6882366539968\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1490 \tSSE =  183.25795255719393\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1500 \tSSE =  181.8418649422579\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1510 \tSSE =  180.43976797492425\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1520 \tSSE =  179.05145944583484\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1530 \tSSE =  177.67674071019502\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1540 \tSSE =  176.31541661715318\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1550 \tSSE =  174.96729542965252\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1560 \tSSE =  173.63218873569875\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1570 \tSSE =  172.309911352151\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1580 \tSSE =  171.00028122228912\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1590 \tSSE =  169.70311930852398\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1600 \tSSE =  168.41824948170614\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1610 \tSSE =  167.14549840854409\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1620 \tSSE =  165.8846954386685\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1630 \tSSE =  164.63567249287382\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1640 \tSSE =  163.39826395402875\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1650 \tSSE =  162.1723065620814\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1660 \tSSE =  160.95763931448704\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1670 \tSSE =  159.75410337326832\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1680 \tSSE =  158.56154197977511\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1690 \tSSE =  157.37980037805494\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1700 \tSSE =  156.20872574757695\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1710 \tSSE =  155.04816714587824\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1720 \tSSE =  153.89797546152704\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1730 \tSSE =  152.75800337762666\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1740 \tSSE =  151.62810534592228\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1750 \tSSE =  150.50813757142464\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1760 \tSSE =  149.39795800732745\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1770 \tSSE =  148.29742635988043\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1780 \tSSE =  147.20640410277815\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1790 \tSSE =  146.1247545005417\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1800 \tSSE =  145.05234264030486\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1810 \tSSE =  143.98903547136\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1820 \tSSE =  142.9347018517803\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1830 \tSSE =  141.88921260139574\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1840 \tSSE =  140.85244056037203\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1850 \tSSE =  139.82426065260813\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1860 \tSSE =  138.80454995313323\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1870 \tSSE =  137.79318775864232\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  1880 \tSSE =  136.79005566025833\n",
      "Accuracy :  93.30000000000001 %\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_train_test(data_set, 0.8)\n",
    "\n",
    "model, SSE_list = train_model(train_data, layers=[50, 10], stop_threshold=0.1, n_iterations=None,\\\n",
    "                learning_rate=1, verbose=True, test_data=test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Accuracy :  98.65 %\n",
      "test\n",
      "Accuracy :  93.30000000000001 %\n"
     ]
    }
   ],
   "source": [
    "# We test our model\n",
    "print(\"train\")\n",
    "train_acc = test_model(train_data, model)\n",
    "print(\"test\")\n",
    "test_results = test_model(test_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 50)\n",
      "(51, 10)\n"
     ]
    }
   ],
   "source": [
    "for param in model:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test recognizing a picture\n",
    "* Now that our model is  trained, we can try it with different pictures to see what our model is capable of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_result(model, X):\n",
    "    \"\"\"\n",
    "    X is an image of size 400 that we can feed to our model\n",
    "    \"\"\"\n",
    "    X = np.reshape(X, (1, 400))\n",
    "    result = feed_forward_batch(X, model)\n",
    "    Y_hat = result[-1][\"post_activation\"]\n",
    "    \n",
    "    predicted = np.argmax(Y_hat, axis=1)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would also like to have a function to see what these numbers look like\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_number(X):\n",
    "    \"\"\"\n",
    "    X should be of size 400, Y should be a number.\n",
    "    \"\"\"\n",
    "    pixels = X.reshape((20, 20))\n",
    "    pixels = np.transpose(pixels)\n",
    "\n",
    "    plt.imshow(pixels, cmap='gray_r',origin='upper')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  7\n"
     ]
    }
   ],
   "source": [
    "X = data_set.loc[3500].drop([\"Label\"]).values\n",
    "draw_number(X)\n",
    "print(\"Prediction : \", get_one_result(model, X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results\n",
    "\n",
    "Now that we have trained our model, we want to figure out what it doesn't do well.\n",
    "We start by isolating all the numbers on which we failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the test\n",
    "test_outputs = test_results[-1][\"post_activation\"]\n",
    "number_predicted = np.argmax(test_outputs, axis=1)\n",
    "\n",
    "# Error will contain all the images that were mispredicted\n",
    "errors = pd.DataFrame()\n",
    "for i, predicted in enumerate(number_predicted):\n",
    "    if test_data.loc[i]['Label'] != predicted:\n",
    "        errors = errors.append(test_data.loc[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected : 5.0\n",
      "Prediction : 6\n"
     ]
    }
   ],
   "source": [
    "check = 8\n",
    "X = errors.iloc[check].drop([\"Label\"]).values\n",
    "draw_number(X)\n",
    "print(\"Expected :\", errors.iloc[check][\"Label\"])\n",
    "print(\"Prediction :\", get_one_result(model, X)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67 entries, 4 to 996\n",
      "Columns: 401 entries, Label to Pixel_99\n",
      "dtypes: float64(401)\n",
      "memory usage: 210.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(errors.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
