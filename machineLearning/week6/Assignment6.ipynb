{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6 : Hand written digits recognition\n",
    "\n",
    "## First step : loading and processing the data\n",
    "Load the images into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 400 entries, Pixel_0 to Pixel_399\n",
      "dtypes: float64(395), int64(5)\n",
      "memory usage: 15.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>Pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_390</th>\n",
       "      <th>Pixel_391</th>\n",
       "      <th>Pixel_392</th>\n",
       "      <th>Pixel_393</th>\n",
       "      <th>Pixel_394</th>\n",
       "      <th>Pixel_395</th>\n",
       "      <th>Pixel_396</th>\n",
       "      <th>Pixel_397</th>\n",
       "      <th>Pixel_398</th>\n",
       "      <th>Pixel_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pixel_0  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  Pixel_7  \\\n",
       "0        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4        0        0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Pixel_8  Pixel_9    ...      Pixel_390  Pixel_391  Pixel_392  Pixel_393  \\\n",
       "0      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "1      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "2      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "3      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "4      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Pixel_394  Pixel_395  Pixel_396  Pixel_397  Pixel_398  Pixel_399  \n",
       "0        0.0        0.0        0.0        0.0        0.0          0  \n",
       "1        0.0        0.0        0.0        0.0        0.0          0  \n",
       "2        0.0        0.0        0.0        0.0        0.0          0  \n",
       "3        0.0        0.0        0.0        0.0        0.0          0  \n",
       "4        0.0        0.0        0.0        0.0        0.0          0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of a dataframe to hold the images\n",
    "data_set = pd.read_csv(\"image_0.txt\", header=None, names=\\\n",
    "                      [\"Pixel_\"+str(x) for x in range(400)])\n",
    "print(data_set.info())\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the labels to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 401 entries, Label to Pixel_399\n",
      "dtypes: float64(395), int64(6)\n",
      "memory usage: 15.3 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_390</th>\n",
       "      <th>Pixel_391</th>\n",
       "      <th>Pixel_392</th>\n",
       "      <th>Pixel_393</th>\n",
       "      <th>Pixel_394</th>\n",
       "      <th>Pixel_395</th>\n",
       "      <th>Pixel_396</th>\n",
       "      <th>Pixel_397</th>\n",
       "      <th>Pixel_398</th>\n",
       "      <th>Pixel_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Pixel_0  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  \\\n",
       "0      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0        0        0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Pixel_7  Pixel_8    ...      Pixel_390  Pixel_391  Pixel_392  Pixel_393  \\\n",
       "0      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "1      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "2      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "3      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "4      0.0      0.0    ...            0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Pixel_394  Pixel_395  Pixel_396  Pixel_397  Pixel_398  Pixel_399  \n",
       "0        0.0        0.0        0.0        0.0        0.0          0  \n",
       "1        0.0        0.0        0.0        0.0        0.0          0  \n",
       "2        0.0        0.0        0.0        0.0        0.0          0  \n",
       "3        0.0        0.0        0.0        0.0        0.0          0  \n",
       "4        0.0        0.0        0.0        0.0        0.0          0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[\"Label\"] = pd.read_csv(\"label.txt\", header=None, names=[\"Label\"])\n",
    "# Replace the 10s with actual zeros\n",
    "def ten_to_zero(x):\n",
    "    if x == 10:\n",
    "        return 0\n",
    "    return x\n",
    "data_set[\"Label\"] = data_set[\"Label\"].apply(func=ten_to_zero)\n",
    "# Reorganize the columns so that Label is first on the list\n",
    "cols = data_set.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "data_set = data_set[cols]\n",
    "\n",
    "print(data_set.info())\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, proportion=0.8):\n",
    "    shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_data = shuffled_data[:int(0.8 * shuffled_data.shape[0])]\\\n",
    "            .reset_index(drop=True)\n",
    "    test_data = shuffled_data[int(0.8 * shuffled_data.shape[0]):]\\\n",
    "            .reset_index(drop=True)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Columns: 401 entries, Label to Pixel_399\n",
      "dtypes: float64(395), int64(6)\n",
      "memory usage: 12.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test the split function\n",
    "train_data, test_data = split_train_test(data_set)\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we define the parameters of our model\n",
    "* We define a function to initialize parameteres randomly\n",
    "* Each layer of neurons should have a parameter matrix of shape (m, n) where m is the size of the output of the previous layer (or the size of the input in the case of the first layer) + 1, to add the intercept, and n is the number of neurons in this layer.\n",
    "\n",
    "### Example\n",
    "For instance if we have a network with 400 inputs, 25 neurons in the first layer and 10 in the second, we should have parameters like so : \n",
    "* First layer : (401, 25)\n",
    "* Second layer : (26, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layers, n_inputs=400):\n",
    "    \"\"\"\n",
    "        layers is a list. Each of its item represents one layer, and \n",
    "    the number it contains is the size of that layer. The last layer\n",
    "    should always have the size of the expected output (in our case 10)\n",
    "        Our model will then apply argmax to these 10 numbers to find out \n",
    "    which digit was detected.\n",
    "    \n",
    "        The return value is a dic containing a numpy array for each set\n",
    "    of parameters\n",
    "    \"\"\"\n",
    "    parameters = []\n",
    "    \n",
    "    slices = [n_inputs] + layers\n",
    "    \n",
    "    # We loop throught the number of layers to generate parameters\n",
    "    # matrix of the appropriate size\n",
    "    for i, layer in enumerate(layers):\n",
    "        \n",
    "        parameters.append(\\\n",
    "        np.random.randn((slices[i]+1), slices[i+1]))\n",
    "        parameters[i] = parameters[i] * 0.01\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 25)\n",
      "(26, 10)\n",
      "-0.024321489332980867\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "layers = [25, 10]\n",
    "params = initialize_parameters(layers)\n",
    "for row in params:\n",
    "    print(row.shape)\n",
    "    \n",
    "print(params[0][0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the feed forward function\n",
    "This step is just a couple of matrix multiplication, which are easy to implement and run very fast thanks to numpy.\n",
    "\n",
    "To make it work, we must first define the sigmoid function that we will\n",
    "be using for activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.power(1 + np.exp(-x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_batch(batch, params):\n",
    "    \"\"\"\n",
    "        Given a batch of inputs, this function will return an equivalent\n",
    "    batch of outputs. The intermediate values are also returned so they\n",
    "    can be cached for back propagation.\n",
    "    \n",
    "    * Inputs : batch must be a numpy array of shape m * 400 where m\n",
    "    represents the batch size, and 400 is the size of the images\n",
    "    \n",
    "    * Outputs : All of the intermediate and final values of our feed_forward\n",
    "    are contained in results. It is a list of dics.\n",
    "    Each dic contains two entries, Xbarbar which is the sum before the \n",
    "    sigmoid activation function, and F which does contain the activation\n",
    "    function\n",
    "    \"\"\"\n",
    "    # X is the matrix of values taht we will feed to the neural\n",
    "    # network\n",
    "    X = np.copy(batch)\n",
    "    image_size = X.shape[0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    for i, param_matrix in enumerate(params):\n",
    "        results_dic = {}\n",
    "        # We pad the batch with a row of ones to create an intercept\n",
    "        Xbar = np.concatenate((np.ones([X.shape[0], 1]), X), axis=1)\n",
    "        # We store the results from before the multiplication with \n",
    "        # the params for the need of the backpropagation\n",
    "        results_dic[\"pre_multi\"] = Xbar\n",
    "        # Then we multiply the padded batch of vectors with the params\n",
    "        Xbarbar = np.dot(Xbar, param_matrix)\n",
    "        # We cache the results for faster backprop\n",
    "        results_dic[\"pre_activation\"] = Xbarbar\n",
    "        # Then we need to apply the activation function to the product\n",
    "        F = sigmoid(Xbarbar)\n",
    "        # We also store the results from after this operation because\n",
    "        # at this point why not\n",
    "        results_dic[\"post_activation\"] = F\n",
    "        # Finally we put F into X to allow for the next step of the loop\n",
    "        X = F\n",
    "        \n",
    "        results.append(results_dic)\n",
    "        \n",
    "    # Once this loop is completed, we should have our output ready\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 400)\n",
      "(4000, 10)\n",
      "[3 3 3 ... 3 3 3]\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "# Test of the feed_forward function\n",
    "print(train_data.drop([\"Label\"], axis=1).values.shape)\n",
    "X = train_data.drop([\"Label\"], axis=1).values\n",
    "Y = train_data[\"Label\"].values\n",
    "results = feed_forward_batch(X, params)\n",
    "Y_hat = results[-1][\"post_activation\"]\n",
    "print(Y_hat.shape)\n",
    "print(np.argmax(Y_hat, axis=1))\n",
    "print(np.argmax(Y_hat, axis=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the back propagation\n",
    "We are now able to run our model to predict a result. We now need to implement the back propagation algorith to modify the parameters in the direction of the right result.\n",
    "\n",
    "* Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_argmax(x):\n",
    "    \"\"\"\n",
    "    First let's make a function to convert a number between 0 and 9\n",
    "    to a vector of numbers between 0 and 1\n",
    "    \"\"\"\n",
    "    return_value = np.zeros((10))\n",
    "    return_value[x] = 1\n",
    "    return return_value\n",
    "\n",
    "def revert_argmax_vectorized(x):\n",
    "    \"\"\"\n",
    "    x is a numpy vector\n",
    "    \"\"\"\n",
    "    return_value = np.zeros((x.shape[0], 10))\n",
    "    \n",
    "    for i, value in enumerate(x):\n",
    "        return_value[i, value] = 1\n",
    "    \n",
    "    return return_value\n",
    "\n",
    "def compute_SSE(Y_hat, Y):\n",
    "    SE = np.power(Y_hat - Y, 2)\n",
    "    SSE = np.sum(SE)\n",
    "    return SSE\n",
    "\n",
    "def compute_cost(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Y_hat and Y must be (m, 10) dimensional matrices or vectors\n",
    "    \"\"\"\n",
    "    assert Y_hat.shape[1] == 10\n",
    "    cost = Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat)\n",
    "    return np.sum(cost) / Y_hat.shape[0]\n",
    "\n",
    "def accuracy_eval(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Y_hat and Y must be matrices of shape (m, 10) where me is the number of examples\n",
    "    \"\"\"\n",
    "    got_it = 0\n",
    "    for i in range(Y_hat.shape[0]):\n",
    "        if np.argmax(Y_hat[i]) == np.argmax(Y[i]):\n",
    "            got_it += 1\n",
    "            \n",
    "    accuracy = got_it / Y_hat.shape[0]\n",
    "    \n",
    "    return accuracy, got_it\n",
    "\n",
    "def test_model(test_data, model):\n",
    "    X_test = test_data.drop([\"Label\"], axis=1).values\n",
    "    Y_test = revert_argmax_vectorized(test_data[\"Label\"].values)\n",
    "\n",
    "    test_results = feed_forward_batch(X_test, model)\n",
    "    \n",
    "    accuracy, _ = accuracy_eval(test_results[-1][\"post_activation\"], Y_test)\n",
    "    print(\"Accuracy : \", accuracy * 100, \"%\")\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Actual back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_layer_back_propagate(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    * Params must be a numpy matrix containing the parameters for\n",
    "    one layer.\n",
    "    * Results contains the result of a layer\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def back_propagate_custom(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    This function will run backwards through the neural net, computing \n",
    "    the derivatives to modify the parameters according to the learning\n",
    "    rate.\n",
    "    \n",
    "    * Y should be a (batch_size, 10) matrix.\n",
    "    * results contains all of the results from the backpropagation,\n",
    "    layer by layer.\n",
    "    \"\"\"\n",
    "    Y_hat = results[-1][\"post_activation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(params, results, Y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    ========= IMPORTANT ===========\n",
    "    This version of the function is not generealisable to different\n",
    "    number of layers.\n",
    "    \n",
    "    This function will run backwards through the neural net, computing \n",
    "    the derivatives to modify the parameters according to the learning\n",
    "    rate.\n",
    "    \n",
    "    * Y should be a (batch_size, 10) matrix.\n",
    "    * results contains all of the results from the backpropagation,\n",
    "    layer by layer.\n",
    "    \"\"\"\n",
    "    Y_hat = results[-1][\"post_activation\"]\n",
    "    \n",
    "    G = results[-1][\"post_activation\"]\n",
    "    Fbar = results[-1][\"pre_multi\"]\n",
    "    F = results[0][\"post_activation\"]\n",
    "    X = results[0][\"pre_multi\"]\n",
    "    W = params[-1][1:]\n",
    "    \n",
    "    # This first version doesn't use a loop and therefore is not capable of handling\n",
    "    # networks of different sizes\n",
    "    dE_dW = np.transpose(Fbar) @ (G - Y) # * G * (1-G)\n",
    "    dE_dW /= Y_hat.shape[0]\n",
    "    \n",
    "    dE_dV = (G - Y) # * G * (1-G)\n",
    "    dE_dV = dE_dV @ np.transpose(W)\n",
    "    dE_dV = dE_dV * F * (1 - F)\n",
    "    dE_dV = np.transpose(X) @ dE_dV\n",
    "    dE_dV /= Y_hat.shape[0]\n",
    "    \n",
    "    # We update the parameters\n",
    "    params[0] -= learning_rate * dE_dV\n",
    "    params[1] -= learning_rate * dE_dW\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la fonction avec un Y de 4\n",
    "new_params = back_propagate(params, results, revert_argmax(4), learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the full algorithm\n",
    " Now that all of the important functions are here, we are ready to create our train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, layers=[25, 10], stop_threshold=0, n_iterations=30,\\\n",
    "                learning_rate=0.1, verbose=True, test_data=None):\n",
    "    \"\"\"\n",
    "    Train_data is the dataframe we have created\n",
    "    If stop threshold is 0 we run for a set number of iterations.\n",
    "    Else, we run until the progress we make on the error is under a certain number or the number of\n",
    "    iterations is reached, whichever comes first\n",
    "    \"\"\"\n",
    "    # First, we initialise the parameters\n",
    "    params = initialize_parameters(layers)\n",
    "    \n",
    "    # Then we split the training data between X and Y\n",
    "    X = train_data.drop([\"Label\"], axis=1).values\n",
    "    Y = revert_argmax_vectorized(train_data[\"Label\"].values)\n",
    "    \n",
    "    # We loop through the iterations\n",
    "    itera = 0\n",
    "    stop = False\n",
    "    SSE_list = []\n",
    "    while not stop:\n",
    "        # We feed the data to the model\n",
    "        results = feed_forward_batch(X, params)\n",
    "        \n",
    "        # We measure the SSE\n",
    "        SSE = compute_SSE(results[-1][\"post_activation\"], Y)\n",
    "        \n",
    "        # We store our SSE so we can make graphs later\n",
    "        SSE_list.append(SSE)\n",
    "        if verbose and itera%10 == 0:\n",
    "            print(\"Iteration : \", itera, \"\\tSSE = \", SSE)\n",
    "            test_model(test_data, params)\n",
    "        \n",
    "        \"\"\"print(\"F bar\", results[-1][\"pre_multi\"][0, :])\n",
    "        print(\"Parameters last layer : \", params[1][0, :])\n",
    "        print(\"Output : \", results[-1][\"post_activation\"][0, :])\"\"\"\n",
    "        params = back_propagate(params, results, Y, learning_rate)\n",
    "        \n",
    "        itera += 1\n",
    "        if n_iterations != None:\n",
    "            if itera >= n_iterations:\n",
    "                stop = True\n",
    "        if len(SSE_list) > 1:\n",
    "            if np.abs(SSE_list[-1] - SSE_list[-2]) < stop_threshold:\n",
    "                stop = True\n",
    "                \n",
    "    return params, SSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output for the first example :  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Iteration :  0 \tSSE =  9896.690851455962\n",
      "Accuracy :  10.2 %\n",
      "Iteration :  10 \tSSE =  3626.0630413498343\n",
      "Accuracy :  9.9 %\n",
      "Iteration :  20 \tSSE =  3603.409657602554\n",
      "Accuracy :  11.600000000000001 %\n",
      "Iteration :  30 \tSSE =  3554.374889938981\n",
      "Accuracy :  38.0 %\n",
      "Iteration :  40 \tSSE =  3392.2491234684667\n",
      "Accuracy :  47.599999999999994 %\n",
      "Iteration :  50 \tSSE =  3034.85235460297\n",
      "Accuracy :  54.7 %\n",
      "Iteration :  60 \tSSE =  2656.078995191045\n",
      "Accuracy :  63.5 %\n",
      "Iteration :  70 \tSSE =  2346.424084861849\n",
      "Accuracy :  70.19999999999999 %\n",
      "Iteration :  80 \tSSE =  2106.2318298744335\n",
      "Accuracy :  74.8 %\n",
      "Iteration :  90 \tSSE =  1902.0745249712684\n",
      "Accuracy :  78.9 %\n",
      "Iteration :  100 \tSSE =  1718.0209968205286\n",
      "Accuracy :  82.1 %\n",
      "Iteration :  110 \tSSE =  1556.9084144388662\n",
      "Accuracy :  83.89999999999999 %\n",
      "Iteration :  120 \tSSE =  1421.451133301391\n",
      "Accuracy :  84.1 %\n",
      "Iteration :  130 \tSSE =  1309.013427561135\n",
      "Accuracy :  84.7 %\n",
      "Iteration :  140 \tSSE =  1214.826725662598\n",
      "Accuracy :  86.1 %\n",
      "Iteration :  150 \tSSE =  1134.5632499411995\n",
      "Accuracy :  86.9 %\n",
      "Iteration :  160 \tSSE =  1065.0192075823338\n",
      "Accuracy :  87.5 %\n",
      "Iteration :  170 \tSSE =  1004.0419207679279\n",
      "Accuracy :  87.7 %\n",
      "Iteration :  180 \tSSE =  950.2497394953299\n",
      "Accuracy :  87.9 %\n",
      "Iteration :  190 \tSSE =  902.7282636353316\n",
      "Accuracy :  88.4 %\n",
      "Iteration :  200 \tSSE =  860.7893695383854\n",
      "Accuracy :  89.3 %\n",
      "Iteration :  210 \tSSE =  823.8246767159046\n",
      "Accuracy :  89.7 %\n",
      "Iteration :  220 \tSSE =  791.244574294866\n",
      "Accuracy :  89.9 %\n",
      "Iteration :  230 \tSSE =  762.4731291155925\n",
      "Accuracy :  90.10000000000001 %\n",
      "Iteration :  240 \tSSE =  736.9666308417902\n",
      "Accuracy :  90.60000000000001 %\n",
      "Iteration :  250 \tSSE =  714.2332213074884\n",
      "Accuracy :  90.5 %\n",
      "Iteration :  260 \tSSE =  693.8439194821237\n",
      "Accuracy :  90.5 %\n",
      "Iteration :  270 \tSSE =  675.4343837009924\n",
      "Accuracy :  90.5 %\n",
      "Iteration :  280 \tSSE =  658.7004154752448\n",
      "Accuracy :  90.5 %\n",
      "Iteration :  290 \tSSE =  643.3904476964133\n",
      "Accuracy :  90.5 %\n",
      "Iteration :  300 \tSSE =  629.2972753670396\n",
      "Accuracy :  90.4 %\n",
      "Iteration :  310 \tSSE =  616.2502620702775\n",
      "Accuracy :  90.60000000000001 %\n",
      "Iteration :  320 \tSSE =  604.1085465068371\n",
      "Accuracy :  90.60000000000001 %\n",
      "Iteration :  330 \tSSE =  592.7553717620107\n",
      "Accuracy :  90.8 %\n",
      "Iteration :  340 \tSSE =  582.0934663757465\n",
      "Accuracy :  90.9 %\n",
      "Iteration :  350 \tSSE =  572.0413319362208\n",
      "Accuracy :  91.0 %\n",
      "Iteration :  360 \tSSE =  562.5302781233441\n",
      "Accuracy :  91.4 %\n",
      "Iteration :  370 \tSSE =  553.5020591895147\n",
      "Accuracy :  91.5 %\n",
      "Iteration :  380 \tSSE =  544.9069881813534\n",
      "Accuracy :  91.5 %\n",
      "Iteration :  390 \tSSE =  536.7024284245445\n",
      "Accuracy :  91.5 %\n",
      "Iteration :  400 \tSSE =  528.8515824752814\n",
      "Accuracy :  91.60000000000001 %\n",
      "Iteration :  410 \tSSE =  521.3225158770722\n",
      "Accuracy :  91.8 %\n",
      "Iteration :  420 \tSSE =  514.0873667325045\n",
      "Accuracy :  91.9 %\n",
      "Iteration :  430 \tSSE =  507.1217027965402\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  440 \tSSE =  500.40399609719316\n",
      "Accuracy :  92.0 %\n",
      "Iteration :  450 \tSSE =  493.91519151683985\n",
      "Accuracy :  92.2 %\n",
      "Iteration :  460 \tSSE =  487.63835075503766\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  470 \tSSE =  481.55835697869554\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  480 \tSSE =  475.66166850438464\n",
      "Accuracy :  92.4 %\n",
      "Iteration :  490 \tSSE =  469.9361122444258\n",
      "Accuracy :  92.5 %\n",
      "Iteration :  500 \tSSE =  464.3707095301569\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  510 \tSSE =  458.95552841457175\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  520 \tSSE =  453.6815577383824\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  530 \tSSE =  448.5405991845089\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  540 \tSSE =  443.5251742966433\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  550 \tSSE =  438.628444036494\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  560 \tSSE =  433.844138931058\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  570 \tSSE =  429.16649823852833\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  580 \tSSE =  424.5902168570822\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  590 \tSSE =  420.11039892931876\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  600 \tSSE =  415.72251726873327\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  610 \tSSE =  411.422377863992\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  620 \tSSE =  407.2060888114444\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  630 \tSSE =  403.07003309501556\n",
      "Accuracy :  92.5 %\n",
      "Iteration :  640 \tSSE =  399.0108446833685\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  650 \tSSE =  395.0253874543552\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  660 \tSSE =  391.1107364928323\n",
      "Accuracy :  92.60000000000001 %\n",
      "Iteration :  670 \tSSE =  387.26416134542546\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  680 \tSSE =  383.48311085893226\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  690 \tSSE =  379.76519928009486\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  700 \tSSE =  376.10819335363726\n",
      "Accuracy :  92.7 %\n",
      "Iteration :  710 \tSSE =  372.5100002206706\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  720 \tSSE =  368.96865598666756\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  730 \tSSE =  365.48231489175106\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  740 \tSSE =  362.0492390702311\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  750 \tSSE =  358.66778892632493\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  760 \tSSE =  355.336414175865\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  770 \tSSE =  352.0536456091804\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  780 \tSSE =  348.8180876203746\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  790 \tSSE =  345.62841152705136\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  800 \tSSE =  342.4833496773067\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  810 \tSSE =  339.3816903126427\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  820 \tSSE =  336.32227313065437\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  830 \tSSE =  333.3039854727769\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  840 \tSSE =  330.32575905142755\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  850 \tSSE =  327.386567127539\n",
      "Accuracy :  92.9 %\n",
      "Iteration :  860 \tSSE =  324.48542205277414\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  870 \tSSE =  321.6213730990578\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  880 \tSSE =  318.7935045097051\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  890 \tSSE =  316.00093371966943\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  900 \tSSE =  313.24280970589484\n",
      "Accuracy :  93.0 %\n",
      "Iteration :  910 \tSSE =  310.518311441338\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  920 \tSSE =  307.8266464372318\n",
      "Accuracy :  93.10000000000001 %\n",
      "Iteration :  930 \tSSE =  305.16704936715917\n",
      "Accuracy :  93.2 %\n",
      "Iteration :  940 \tSSE =  302.53878077333263\n",
      "Accuracy :  93.2 %\n",
      "Iteration :  950 \tSSE =  299.9411258601165\n",
      "Accuracy :  93.30000000000001 %\n",
      "Iteration :  960 \tSSE =  297.37339338241463\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  970 \tSSE =  294.8349146372591\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  980 \tSSE =  292.32504256600095\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  990 \tSSE =  289.8431509721987\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1000 \tSSE =  287.3886338568809\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1010 \tSSE =  284.9609048686454\n",
      "Accuracy :  93.4 %\n",
      "Iteration :  1020 \tSSE =  282.55939686136276\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1030 \tSSE =  280.18356154742975\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1040 \tSSE =  277.8328692299343\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1050 \tSSE =  275.5068085931342\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1060 \tSSE =  273.2048865276669\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1070 \tSSE =  270.92662796522944\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1080 \tSSE =  268.6715756973341\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1090 \tSSE =  266.43929015426824\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1100 \tSSE =  264.2293491235768\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1110 \tSSE =  262.04134739203556\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1120 \tSSE =  259.87489630088794\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1130 \tSSE =  257.7296232106166\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1140 \tSSE =  255.60517087816686\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1150 \tSSE =  253.50119675579788\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1160 \tSSE =  251.41737222607367\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1170 \tSSE =  249.3533817915295\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1180 \tSSE =  247.30892223998777\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1190 \tSSE =  245.28370180725778\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1200 \tSSE =  243.2774393581177\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1210 \tSSE =  241.2898636042502\n",
      "Accuracy :  93.60000000000001 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  1220 \tSSE =  239.32071237451305\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1230 \tSSE =  237.36973194894884\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1240 \tSSE =  235.4366764636577\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1250 \tSSE =  233.52130738942995\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1260 \tSSE =  231.62339308315865\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1270 \tSSE =  229.74270840774165\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1280 \tSSE =  227.8790344135749\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1290 \tSSE =  226.03215807289592\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1300 \tSSE =  224.2018720571495\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1310 \tSSE =  222.38797454716413\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1320 \tSSE =  220.59026906615128\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1330 \tSSE =  218.80856432626464\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1340 \tSSE =  217.04267408055557\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1350 \tSSE =  215.29241697351895\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1360 \tSSE =  213.55761638492433\n",
      "Accuracy :  93.5 %\n",
      "Iteration :  1370 \tSSE =  211.83810026317283\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1380 \tSSE =  210.13370094592165\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1390 \tSSE =  208.44425496710863\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1400 \tSSE =  206.76960285073483\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1410 \tSSE =  205.10958889278686\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1420 \tSSE =  203.4640609334854\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1430 \tSSE =  201.8328701226231\n",
      "Accuracy :  93.60000000000001 %\n",
      "Iteration :  1440 \tSSE =  200.21587068111427\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1450 \tSSE =  198.6129196620338\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1460 \tSSE =  197.02387671440516\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1470 \tSSE =  195.44860385283226\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1480 \tSSE =  193.88696523579176\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1490 \tSSE =  192.33882695505076\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1500 \tSSE =  190.80405683826947\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1510 \tSSE =  189.28252426643172\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1520 \tSSE =  187.77410000732957\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1530 \tSSE =  186.27865606593969\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1540 \tSSE =  184.7960655521759\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1550 \tSSE =  183.3262025661968\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1560 \tSSE =  181.86894210119434\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1570 \tSSE =  180.4241599633829\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1580 \tSSE =  178.99173270875883\n",
      "Accuracy :  93.7 %\n",
      "Iteration :  1590 \tSSE =  177.57153759608792\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1600 \tSSE =  176.16345255551013\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1610 \tSSE =  174.76735617211187\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1620 \tSSE =  173.38312768380158\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1630 \tSSE =  172.0106469928271\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1640 \tSSE =  170.64979469028498\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1650 \tSSE =  169.30045209298373\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1660 \tSSE =  167.96250129203423\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1670 \tSSE =  166.635825212536\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1680 \tSSE =  165.32030768371186\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1690 \tSSE =  164.01583351880402\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1700 \tSSE =  162.7222886039837\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1710 \tSSE =  161.43955999543905\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1720 \tSSE =  160.16753602369178\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1730 \tSSE =  158.90610640405666\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1740 \tSSE =  157.65516235199664\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1750 \tSSE =  156.4145967019496\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1760 \tSSE =  155.18430402801647\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1770 \tSSE =  153.9641807647119\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1780 \tSSE =  152.75412532579827\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1790 \tSSE =  151.55403821906646\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1800 \tSSE =  150.36382215479904\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1810 \tSSE =  149.18338214557016\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1820 \tSSE =  148.0126255950106\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1830 \tSSE =  146.8514623732052\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1840 \tSSE =  145.6998048765028\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1850 \tSSE =  144.55756806970777\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1860 \tSSE =  143.42466950888644\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1870 \tSSE =  142.30102934336418\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1880 \tSSE =  141.18657029589173\n",
      "Accuracy :  93.8 %\n",
      "Iteration :  1890 \tSSE =  140.0812176204217\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1900 \tSSE =  138.9848990374371\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1910 \tSSE =  137.8975446472963\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1920 \tSSE =  136.81908682259126\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1930 \tSSE =  135.7494600810274\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1940 \tSSE =  134.68860094081586\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1950 \tSSE =  133.6364477609991\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1960 \tSSE =  132.5929405694915\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1970 \tSSE =  131.55802088189927\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1980 \tSSE =  130.53163151437656\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  1990 \tSSE =  129.51371639386903\n",
      "Accuracy :  93.89999999999999 %\n",
      "Iteration :  2000 \tSSE =  128.5042203690948\n",
      "Accuracy :  93.89999999999999 %\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_train_test(data_set, 0.8)\n",
    "\n",
    "print(\"Expected Output for the first example : \",\\\n",
    "      revert_argmax(train_data[\"Label\"].values[0]))\n",
    "model, SSE_list = train_model(train_data, layers=[50, 10], stop_threshold=0.1, n_iterations=None,\\\n",
    "                learning_rate=1, verbose=True, test_data=test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  93.89999999999999 %\n"
     ]
    }
   ],
   "source": [
    "# We test our model\n",
    "\n",
    "    \n",
    "test_results = test_model(test_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 25)\n",
      "(26, 10)\n"
     ]
    }
   ],
   "source": [
    "for param in model:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test recognizing a picture\n",
    "* Now that our model is  trained, we can try it with different pictures to see what our model is capable of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_result(model, X):\n",
    "    \"\"\"\n",
    "    X is an image of size 400 that we can feed to our model\n",
    "    \"\"\"\n",
    "    X = np.reshape(X, (1, 400))\n",
    "    result = feed_forward_batch(X, model)\n",
    "    Y = result[-1][\"post_activation\"]\n",
    "    \n",
    "    predicted = np.argmax(Y, axis=1)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would also like to have a function to see what these numbers look like\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "\n",
    "def draw_number(X):\n",
    "    \"\"\"\n",
    "    X should be of size 400, Y should be a number.\n",
    "    \"\"\"\n",
    "    pixels = X.reshape((20, 20))\n",
    "    pixels = ndimage.rotate(pixels, 90)\n",
    "\n",
    "    plt.imshow(pixels, cmap='gray_r',origin='lower')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  9\n"
     ]
    }
   ],
   "source": [
    "X = data_set.loc[4800].drop([\"Label\"]).values\n",
    "draw_number(X)\n",
    "print(\"Prediction : \", get_one_result(model, X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results\n",
    "\n",
    "Now that we have trained our model, we want to figure out what it doesn't do well.\n",
    "We start by isolating all the numbers on which we failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the test\n",
    "test_outputs = test_results[-1][\"post_activation\"]\n",
    "number_predicted = np.argmax(test_outputs, axis=1)\n",
    "\n",
    "# Error will contain all the images that were mispredicted\n",
    "errors = pd.DataFrame()\n",
    "for i, predicted in enumerate(number_predicted):\n",
    "    if test_data.loc[i]['Label'] != predicted:\n",
    "        errors = errors.append(test_data.loc[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected : 1.0\n",
      "Prediction : 2\n"
     ]
    }
   ],
   "source": [
    "check = 20\n",
    "X = errors.iloc[check].drop([\"Label\"]).values\n",
    "draw_number(X)\n",
    "print(\"Expected :\", errors.iloc[check][\"Label\"])\n",
    "print(\"Prediction :\", get_one_result(model, X)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61 entries, 1 to 996\n",
      "Columns: 401 entries, Label to Pixel_99\n",
      "dtypes: float64(401)\n",
      "memory usage: 191.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(errors.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
