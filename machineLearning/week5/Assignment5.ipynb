{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning assignment week 5\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jacques', 'a', 'dit']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a dit</td>\n",
       "      <td>Jacques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message   Target\n",
       "0   a dit  Jacques"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for the organisation of the data set\n",
    "words = \"Jacques a dit\".split(\" \")\n",
    "print(words)\n",
    "df = pd.DataFrame(data=[[' '.join(words[1:]), words[0]]],\\\n",
    "                  columns=[\"message\", \"Target\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      "Message    5000 non-null object\n",
      "Target     5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n",
      "None\n",
      "                                             Message Target\n",
      "0                   Yup i've finished c Ã¼ there...\\n    ham\n",
      "1             Remember to ask alex about his pizza\\n    ham\n",
      "2                     No da..today also i forgot..\\n    ham\n",
      "3  Ola would get back to you maybe not today but ...    ham\n",
      "4  Fwiw the reason I'm only around when it's time...    ham\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=[\"Message\", \"Target\"])\n",
    "\n",
    "counter = 0\n",
    "with open(\"messages.txt\") as messages_file:\n",
    "    for line in messages_file:\n",
    "        words = line.split(\"\\t\")\n",
    "        data.loc[counter] = [words[1], words[0]]\n",
    "        counter += 1\n",
    "        \n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate between train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 2 columns):\n",
      "Message    3999 non-null object\n",
      "Target     3999 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 62.6+ KB\n",
      "Train :  None\n",
      "                                             Message Target\n",
      "0  Dorothy@kiefer.com (Bank of Granite issues Str...   spam\n",
      "1  says the  &lt;#&gt;  year old with a man and m...    ham\n",
      "2                       I will come to ur home now\\n    ham\n",
      "3  Free any day but i finish at 6 on mon n thurs....    ham\n",
      "4                        Will you be here for food\\n    ham\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 2 columns):\n",
      "Message    1001 non-null object\n",
      "Target     1001 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.7+ KB\n",
      "Test :  None\n"
     ]
    }
   ],
   "source": [
    "train_proportion = 0.8\n",
    "\n",
    "\n",
    "train_data = data[1 - int(data.shape[0] * train_proportion):].reset_index(drop=True)\n",
    "test_data = data[:1-int(data.shape[0] * train_proportion)].reset_index(drop=True)\n",
    "print(\"Train : \", train_data.info())\n",
    "print(train_data.head())\n",
    "print(\"Test : \", test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_dictionnary(data, most_commons):\n",
    "    \"\"\"\n",
    "        Data is a pandas DataFrame generated earlier\n",
    "        most_common represents the number of most common words we want to take\n",
    "    \"\"\"\n",
    "    # Generate a list of words\n",
    "    word_list = []\n",
    "    for i in range(data.shape[0]):\n",
    "        message = data.at[i, \"Message\"]\n",
    "        # To add : remove punctuation from message\n",
    "        words = message.split(\" \")\n",
    "        \n",
    "        word_list += words\n",
    "        \n",
    "    word_dic = Counter(word_list)\n",
    "    for item in list(word_dic):\n",
    "        if item.isalpha() == False or len(item) == 1:\n",
    "            del word_dic[item]\n",
    "            \n",
    "    return word_dic.most_common(most_commons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size = 3000\n",
    "\n",
    "words_dic = make_dictionnary(train_data, dic_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the data sets\n",
    "#### Turn Spam and ham into 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target\n",
      "0  Dorothy@kiefer.com (Bank of Granite issues Str...       1\n",
      "1  says the  &lt;#&gt;  year old with a man and m...       0\n",
      "2                       I will come to ur home now\\n       0\n",
      "3  Free any day but i finish at 6 on mon n thurs....       0\n",
      "4                        Will you be here for food\\n       0\n"
     ]
    }
   ],
   "source": [
    "def parse_target(data):\n",
    "    data[\"Target\"] = pd.Categorical(data[\"Target\"]).codes\n",
    "    return data\n",
    "    \n",
    "print(parse_target(train_data).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn each message into a vector by using the dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, words_dic):\n",
    "    feature_matrix = np.zeros((data.shape[0], len(words_dic)))\n",
    "    \n",
    "    messageID = 0\n",
    "    for line in data[\"Message\"]:\n",
    "        words = line.split(\" \")\n",
    "        for word in words:\n",
    "            for i, d in enumerate(words_dic):\n",
    "                if d[0] == word:\n",
    "                    feature_matrix[messageID, i] += 1\n",
    "        messageID += 1\n",
    "        \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "train_features = extract_features(train_data, words_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Naive Bayes\n",
    "\n",
    "For this part, we will use the Bayes formula.\n",
    "* For each message, we write p(spam) the probability that this message is a spam, and p(x0) the probability that the word 0 is in that message.\n",
    "* p(spam | x0) = (p(x0 | spam) * p(spam)) / p(x0).\n",
    "* We know p(x0) and p(spam) trivially by counting how many instances of each are in our training set, and we can find p(x0 | spam) by looking for each word at how often they appear in spams.\n",
    "\n",
    "We thus have 3 steps to train a naive Bayes classifier for our spam filter :\n",
    "* Find p(X), for each word, the probability it is in a message.\n",
    "* Find p(spam), for each message, the probability it is a spam.\n",
    "* Find p(X | spam) : for each word, the probability it is in a spam.\n",
    "\n",
    "##### Find P(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13703425856464116\n"
     ]
    }
   ],
   "source": [
    "p_spam = train_data[\"Target\"][train_data[\"Target\"] == 1].count() / train_data.shape[0]\n",
    "print(p_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find p(X)\n",
    "* For each word, find the probability that it is x amount of time in any given message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our p_X.\n",
    "# It is a matrix with each word as a line and the amount of time it appears\n",
    "# in a message as a column\n",
    "\n",
    "# This function should have run using extract features\n",
    "def count_nb_instances_for_each_word(data, words_dic, max_amount=5):\n",
    "    # Variables\n",
    "    retour = np.zeros((len(words_dic), max_amount))\n",
    "    \n",
    "    # Loop through each word of the dictionnary\n",
    "    for i, dic_word in enumerate(words_dic):\n",
    "        # Loop through each message\n",
    "        for message in data[\"Message\"]:\n",
    "            instance_count = 0\n",
    "            words = message.split(\" \")\n",
    "            \n",
    "            # Loop tjrough each word of the message\n",
    "            for word in words:\n",
    "                if word == dic_word[0]:\n",
    "                    instance_count += 1\n",
    "            if instance_count >= max_amount:\n",
    "                instance_count = max_amount - 1\n",
    "            retour[i, instance_count] += 1\n",
    "    \n",
    "    # Turn the matrice into probabi p\n",
    "    retour /= np.sum(retour[0, :])\n",
    "    \n",
    "    return retour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the above function to find the number of instances of each word in all messages in training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n"
     ]
    }
   ],
   "source": [
    "p_X = count_nb_instances_for_each_word(train_data, words_dic)\n",
    "\n",
    "print(p_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70667667 0.22455614 0.05151288 0.01250313 0.00475119]\n"
     ]
    }
   ],
   "source": [
    "print(p_X[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n",
      "[0.4379562  0.3850365  0.12591241 0.04562044 0.00547445]\n"
     ]
    }
   ],
   "source": [
    "p_X_spam = count_nb_instances_for_each_word(\\\n",
    "            train_data[train_data[\"Target\"] == 1], words_dic)\n",
    "\n",
    "print(p_X_spam.shape)\n",
    "print(p_X_spam[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70667667 0.22455614 0.05151288 0.01250313 0.00475119]\n"
     ]
    }
   ],
   "source": [
    "np.sum(p_X[0, :])\n",
    "print((p_X/ np.sum(p_X[0, :]))[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do now is to apply the formula thanks to np.apply_formula.please().no_really_I_dont_know_how_to_do_it(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n",
      "[0.08492569 0.23496658 0.33495139 0.4999996  0.1578944 ]\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.00000001\n",
    "# We now have all the elements to give to each word a probability\n",
    "p_spam_X = np.divide(p_X_spam * p_spam, p_X + epsilon)\n",
    "print(p_spam_X.shape)\n",
    "print(p_spam_X[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try our model on the test_data\n",
    "* For each word, we have found the probability that its presence indicates the message is a spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message Target\n",
      "0                   Yup i've finished c Ã¼ there...\\n    ham\n",
      "1             Remember to ask alex about his pizza\\n    ham\n",
      "2                     No da..today also i forgot..\\n    ham\n",
      "3  Ola would get back to you maybe not today but ...    ham\n",
      "4  Fwiw the reason I'm only around when it's time...    ham\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target\n",
      "0                   Yup i've finished c Ã¼ there...\\n       0\n",
      "1             Remember to ask alex about his pizza\\n       0\n",
      "2                     No da..today also i forgot..\\n       0\n",
      "3  Ola would get back to you maybe not today but ...       0\n",
      "4  Fwiw the reason I'm only around when it's time...       0\n"
     ]
    }
   ],
   "source": [
    "test_data = parse_target(test_data)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features of the test_data\n",
    "test_features = extract_features(test_data, words_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(test_features[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001,)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Loop through test_features, and find the mean of probabilities\n",
    "score_probas = np.zeros(test_data.shape[0])\n",
    "for i, line in enumerate(test_features):\n",
    "\n",
    "    word_count = 0\n",
    "    for j, apparition in enumerate(line):\n",
    "        if apparition > 0:\n",
    "            # + 1 because multiple iteration of the same word\n",
    "            # is already taken in consideration in p_spam_X\n",
    "            word_count += 1\n",
    "            if apparition >= p_spam_X.shape[1]:\n",
    "                apparition = p_spam_X.shape[1] - 1\n",
    "                \n",
    "            score_probas[i] += p_spam_X[j, int(apparition)]\n",
    "            \n",
    "    score_probas[i] /= word_count\n",
    "    \n",
    "print(score_probas.shape)\n",
    "print(score_probas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.06250965 0.07706761 ... 0.07470045 0.11431392 0.05490337]\n"
     ]
    }
   ],
   "source": [
    "print(score_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Result'] = np.around(score_probas)\n",
    "test_data['Proba'] = score_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target  Result     Proba\n",
      "0                   Yup i've finished c Ã¼ there...\\n       0     0.0  0.000000\n",
      "1             Remember to ask alex about his pizza\\n       0     0.0  0.062510\n",
      "2                     No da..today also i forgot..\\n       0     0.0  0.077068\n",
      "3  Ola would get back to you maybe not today but ...       0     0.0  0.154623\n",
      "4  Fwiw the reason I'm only around when it's time...       0     0.0  0.077037\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 4 columns):\n",
      "Message    1001 non-null object\n",
      "Target     1001 non-null int8\n",
      "Result     970 non-null float64\n",
      "Proba      970 non-null float64\n",
      "dtypes: float64(2), int8(1), object(1)\n",
      "memory usage: 24.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Message  Target  Result  \\\n",
      "0                      Yup i've finished c Ã¼ there...\\n       0     0.0   \n",
      "1                Remember to ask alex about his pizza\\n       0     0.0   \n",
      "2                        No da..today also i forgot..\\n       0     0.0   \n",
      "3     Ola would get back to you maybe not today but ...       0     0.0   \n",
      "4     Fwiw the reason I'm only around when it's time...       0     0.0   \n",
      "5     Hello, my boytoy! I made it home and my consta...       0     0.0   \n",
      "6                Congrats kano..whr s the treat maga?\\n       0     0.0   \n",
      "7                                Who u talking about?\\n       0     0.0   \n",
      "8                                              Yup...\\n       0     NaN   \n",
      "9                                               Ok...\\n       0     NaN   \n",
      "10    U wake up already? Wat u doing? U picking us u...       0     0.0   \n",
      "11    Yunny i'm walking in citylink now Ã¼ faster com...       0     0.0   \n",
      "12                                Er yep sure. Props?\\n       0     0.0   \n",
      "13    Hiya , have u been paying money into my accoun...       0     0.0   \n",
      "15      Ok ill send you with in  &lt;DECIMAL&gt;  ok.\\n       0     0.0   \n",
      "16    Bognor it is! Should be splendid at this time ...       0     0.0   \n",
      "17                             Yes.i'm in office da:)\\n       0     0.0   \n",
      "18                             Sorry, I'll call later\\n       0     0.0   \n",
      "19    Joy's father is John. Then John is the NAME of...       0     0.0   \n",
      "20         Ok. I only ask abt e movie. U wan ktv oso?\\n       0     0.0   \n",
      "21    Misplaced your number and was sending texts to...       0     0.0   \n",
      "22                             Sorry, I'll call later\\n       0     0.0   \n",
      "23    Dunno lei... I might b eatin wif my frens... I...       0     0.0   \n",
      "24                             Sorry, I'll call later\\n       0     0.0   \n",
      "26    Say this slowly.? GOD,I LOVE YOU &amp; I NEED ...       0     0.0   \n",
      "27     Do u noe how 2 send files between 2 computers?\\n       0     0.0   \n",
      "28    Mmmmm ... I loved waking to your words this mo...       0     0.0   \n",
      "29                   jay says he'll put in  &lt;#&gt;\\n       0     0.0   \n",
      "30    Can you just come in for a sec? There's somebo...       0     0.0   \n",
      "31                 So the sun is anti sleep medicine.\\n       0     0.0   \n",
      "...                                                 ...     ...     ...   \n",
      "967   Actually fuck that, just do whatever, do find ...       0     0.0   \n",
      "969   yay! finally lol. i missed our cinema trip las...       0     0.0   \n",
      "970   All day working day:)except saturday and sunda...       0     0.0   \n",
      "971                       aathi..where are you dear..\\n       0     0.0   \n",
      "972   Heart is empty without love.. Mind is empty wi...       0     0.0   \n",
      "973   I think Iâm waiting for the same bus! Inform m...       0     0.0   \n",
      "974                   You getting back any time soon?\\n       0     0.0   \n",
      "975            , how's things? Just a quick question.\\n       0     0.0   \n",
      "976   Night has ended for another day, morning has c...       0     0.0   \n",
      "977   I can probably come by, everybody's done aroun...       0     0.0   \n",
      "978   I got it before the new year cos yetunde said ...       0     0.0   \n",
      "979   I can ask around but there's not a lot in term...       0     0.0   \n",
      "980   Be sure to check your yahoo email. We sent pho...       0     0.0   \n",
      "981                         What was she looking for?\\n       0     0.0   \n",
      "982                          Wherre's my boytoy ? :-(\\n       0     0.0   \n",
      "984   Hello, my love! How goes that day ? I wish you...       0     0.0   \n",
      "985   Tell my  bad character which u Dnt lik in me. ...       0     0.0   \n",
      "986   No:-)i got rumour that you going to buy apartm...       0     0.0   \n",
      "987                  Yeah, probably earlier than that\\n       0     0.0   \n",
      "988                     Change windows logoff sound..\\n       0     0.0   \n",
      "989               Still i have not checked it da. . .\\n       0     0.0   \n",
      "990                            I'm also came to room.\\n       0     0.0   \n",
      "991   Huh but i got lesson at 4 lei n i was thinkin ...       0     0.0   \n",
      "992                                               Ok.\\n       0     NaN   \n",
      "993   I will reach office around  &lt;DECIMAL&gt; . ...       0     0.0   \n",
      "994                   Cool, text me when you head out\\n       0     0.0   \n",
      "997   Happy birthday... May u find ur prince charmin...       0     0.0   \n",
      "998   Oh, the grand is having a bit of a party but i...       0     0.0   \n",
      "999   You said to me before i went back to bed that ...       0     0.0   \n",
      "1000  I hope you arnt pissed off but id would really...       0     0.0   \n",
      "\n",
      "         Proba  \n",
      "0     0.000000  \n",
      "1     0.062510  \n",
      "2     0.077068  \n",
      "3     0.154623  \n",
      "4     0.077037  \n",
      "5     0.109973  \n",
      "6     0.124428  \n",
      "7     0.166664  \n",
      "8          NaN  \n",
      "9          NaN  \n",
      "10    0.023888  \n",
      "11    0.079785  \n",
      "12    0.000000  \n",
      "13    0.246923  \n",
      "15    0.145125  \n",
      "16    0.146520  \n",
      "17    0.042194  \n",
      "18    0.485106  \n",
      "19    0.197890  \n",
      "20    0.062500  \n",
      "21    0.147520  \n",
      "22    0.485106  \n",
      "23    0.041385  \n",
      "24    0.485106  \n",
      "26    0.146483  \n",
      "27    0.142337  \n",
      "28    0.107981  \n",
      "29    0.034255  \n",
      "30    0.106618  \n",
      "31    0.066086  \n",
      "...        ...  \n",
      "967   0.089808  \n",
      "969   0.378208  \n",
      "970   0.092157  \n",
      "971   0.179158  \n",
      "972   0.022519  \n",
      "973   0.095037  \n",
      "974   0.187283  \n",
      "975   0.125000  \n",
      "976   0.070250  \n",
      "977   0.040417  \n",
      "978   0.142609  \n",
      "979   0.157659  \n",
      "980   0.114447  \n",
      "981   0.114318  \n",
      "982   0.010671  \n",
      "984   0.068571  \n",
      "985   0.133080  \n",
      "986   0.069372  \n",
      "987   0.000000  \n",
      "988   0.000000  \n",
      "989   0.097070  \n",
      "990   0.090227  \n",
      "991   0.034802  \n",
      "992        NaN  \n",
      "993   0.205098  \n",
      "994   0.138284  \n",
      "997   0.098377  \n",
      "998   0.074700  \n",
      "999   0.114314  \n",
      "1000  0.054903  \n",
      "\n",
      "[877 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[test_data['Target'] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9140859140859141\n",
      "Precision : 1.0\n",
      "Recall : 0.5564516129032258\n",
      "[[ 69.   0.]\n",
      " [ 55. 846.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(data):\n",
    "    \"\"\"\n",
    "    data is DataFrame containing the columns Target and Result\n",
    "    \"\"\"\n",
    "    confusion_matrix = np.zeros((2, 2))\n",
    "    \n",
    "    confusion_matrix[0, 0] = data\\\n",
    "    [data['Target'] == 1][data['Result'] == 1.0]['Target'].count()\n",
    "    \n",
    "    confusion_matrix[1, 1] = data\\\n",
    "    [data['Target'] == 0][data['Result'] == 0.0]['Target'].count()\n",
    "    \n",
    "    confusion_matrix[1, 0] = data\\\n",
    "    [data['Target'] == 1][data['Result'] == 0.0]['Target'].count()\n",
    "    \n",
    "    confusion_matrix[0, 1] = data\\\n",
    "    [data['Target'] == 0][data['Result'] == 1.0]['Target'].count()\n",
    "    \n",
    "    print(\"Accuracy : \",\\\n",
    "          (confusion_matrix[0, 0] + confusion_matrix[1, 1])/data.shape[0])\n",
    "    print(\"Precision :\",\\\n",
    "    (confusion_matrix[0, 0])/np.sum(confusion_matrix[0, :]))\n",
    "    print(\"Recall :\",\\\n",
    "    (confusion_matrix[0, 0])/np.sum(confusion_matrix[:, 0]))\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(test_data)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
