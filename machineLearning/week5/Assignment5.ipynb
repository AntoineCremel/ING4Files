{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning assignment week 5\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jacques', 'a', 'dit']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a dit</td>\n",
       "      <td>Jacques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message   Target\n",
       "0   a dit  Jacques"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for the organisation of the data set\n",
    "words = \"Jacques a dit\".split(\" \")\n",
    "print(words)\n",
    "df = pd.DataFrame(data=[[' '.join(words[1:]), words[0]]],\\\n",
    "                  columns=[\"message\", \"Target\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      "Message    5000 non-null object\n",
      "Target     5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n",
      "None\n",
      "                                             Message Target\n",
      "0                   Yup i've finished c ü there...\\n    ham\n",
      "1             Remember to ask alex about his pizza\\n    ham\n",
      "2                     No da..today also i forgot..\\n    ham\n",
      "3  Ola would get back to you maybe not today but ...    ham\n",
      "4  Fwiw the reason I'm only around when it's time...    ham\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=[\"Message\", \"Target\"])\n",
    "\n",
    "counter = 0\n",
    "with open(\"messages.txt\") as messages_file:\n",
    "    for line in messages_file:\n",
    "        words = line.split(\"\\t\")\n",
    "        data.loc[counter] = [words[1], words[0]]\n",
    "        counter += 1\n",
    "        \n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate between train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 2 columns):\n",
      "Message    3999 non-null object\n",
      "Target     3999 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 62.6+ KB\n",
      "Train :  None\n",
      "                                             Message Target\n",
      "0  Dorothy@kiefer.com (Bank of Granite issues Str...   spam\n",
      "1  says the  &lt;#&gt;  year old with a man and m...    ham\n",
      "2                       I will come to ur home now\\n    ham\n",
      "3  Free any day but i finish at 6 on mon n thurs....    ham\n",
      "4                        Will you be here for food\\n    ham\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 2 columns):\n",
      "Message    1001 non-null object\n",
      "Target     1001 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.7+ KB\n",
      "Test :  None\n"
     ]
    }
   ],
   "source": [
    "train_proportion = 0.8\n",
    "\n",
    "\n",
    "train_data = data[1 - int(data.shape[0] * train_proportion):].reset_index(drop=True)\n",
    "test_data = data[:1-int(data.shape[0] * train_proportion)].reset_index(drop=True)\n",
    "print(\"Train : \", train_data.info())\n",
    "print(train_data.head())\n",
    "print(\"Test : \", test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_dictionnary(data, most_commons):\n",
    "    \"\"\"\n",
    "        Data is a pandas DataFrame generated earlier\n",
    "        most_common represents the number of most common words we want to take\n",
    "    \"\"\"\n",
    "    # Generate a list of words\n",
    "    word_list = []\n",
    "    for i in range(data.shape[0]):\n",
    "        message = data.at[i, \"Message\"]\n",
    "        # To add : remove punctuation from message\n",
    "        words = message.split(\" \")\n",
    "        \n",
    "        word_list += words\n",
    "        \n",
    "    word_dic = Counter(word_list)\n",
    "    for item in list(word_dic):\n",
    "        if item.isalpha() == False or len(item) == 1:\n",
    "            del word_dic[item]\n",
    "            \n",
    "    return word_dic.most_common(most_commons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size = 3000\n",
    "\n",
    "words_dic = make_dictionnary(train_data, dic_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the data sets\n",
    "#### Turn Spam and ham into 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target\n",
      "0  Dorothy@kiefer.com (Bank of Granite issues Str...       1\n",
      "1  says the  &lt;#&gt;  year old with a man and m...       0\n",
      "2                       I will come to ur home now\\n       0\n",
      "3  Free any day but i finish at 6 on mon n thurs....       0\n",
      "4                        Will you be here for food\\n       0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup i've finished c ü there...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember to ask alex about his pizza\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No da..today also i forgot..\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ola would get back to you maybe not today but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fwiw the reason I'm only around when it's time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello, my boytoy! I made it home and my consta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Congrats kano..whr s the treat maga?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who u talking about?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yup...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ok...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U wake up already? Wat u doing? U picking us u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yunny i'm walking in citylink now ü faster com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Er yep sure. Props?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hiya , have u been paying money into my accoun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>U have won a nokia 6230 plus a free digital ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ok ill send you with in  &amp;lt;DECIMAL&amp;gt;  ok.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bognor it is! Should be splendid at this time ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yes.i'm in office da:)\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sorry, I'll call later\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Joy's father is John. Then John is the NAME of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ok. I only ask abt e movie. U wan ktv oso?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Misplaced your number and was sending texts to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sorry, I'll call later\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dunno lei... I might b eatin wif my frens... I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sorry, I'll call later\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FREE entry into our £250 weekly comp just send...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Say this slowly.? GOD,I LOVE YOU &amp;amp; I NEED ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Do u noe how 2 send files between 2 computers?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mmmmm ... I loved waking to your words this mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jay says he'll put in  &amp;lt;#&amp;gt;\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>aathi..where are you dear..\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Heart is empty without love.. Mind is empty wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>I think I‘m waiting for the same bus! Inform m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>You getting back any time soon?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>, how's things? Just a quick question.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Night has ended for another day, morning has c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>I can probably come by, everybody's done aroun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>I got it before the new year cos yetunde said ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>I can ask around but there's not a lot in term...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Be sure to check your yahoo email. We sent pho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>What was she looking for?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Wherre's my boytoy ? :-(\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Do you want a NEW video phone750 anytime any n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Hello, my love! How goes that day ? I wish you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Tell my  bad character which u Dnt lik in me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>No:-)i got rumour that you going to buy apartm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Yeah, probably earlier than that\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Change windows logoff sound..\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Still i have not checked it da. . .\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>I'm also came to room.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Huh but i got lesson at 4 lei n i was thinkin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Ok.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>I will reach office around  &amp;lt;DECIMAL&amp;gt; . ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Cool, text me when you head out\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>You are being contacted by our dating service ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Wan2 win a Meet+Greet with Westlife 4 U or a m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Happy birthday... May u find ur prince charmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Oh, the grand is having a bit of a party but i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You said to me before i went back to bed that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>I hope you arnt pissed off but id would really...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message  Target\n",
       "0                      Yup i've finished c ü there...\\n       0\n",
       "1                Remember to ask alex about his pizza\\n       0\n",
       "2                        No da..today also i forgot..\\n       0\n",
       "3     Ola would get back to you maybe not today but ...       0\n",
       "4     Fwiw the reason I'm only around when it's time...       0\n",
       "5     Hello, my boytoy! I made it home and my consta...       0\n",
       "6                Congrats kano..whr s the treat maga?\\n       0\n",
       "7                                Who u talking about?\\n       0\n",
       "8                                              Yup...\\n       0\n",
       "9                                               Ok...\\n       0\n",
       "10    U wake up already? Wat u doing? U picking us u...       0\n",
       "11    Yunny i'm walking in citylink now ü faster com...       0\n",
       "12                                Er yep sure. Props?\\n       0\n",
       "13    Hiya , have u been paying money into my accoun...       0\n",
       "14    U have won a nokia 6230 plus a free digital ca...       1\n",
       "15      Ok ill send you with in  &lt;DECIMAL&gt;  ok.\\n       0\n",
       "16    Bognor it is! Should be splendid at this time ...       0\n",
       "17                             Yes.i'm in office da:)\\n       0\n",
       "18                             Sorry, I'll call later\\n       0\n",
       "19    Joy's father is John. Then John is the NAME of...       0\n",
       "20         Ok. I only ask abt e movie. U wan ktv oso?\\n       0\n",
       "21    Misplaced your number and was sending texts to...       0\n",
       "22                             Sorry, I'll call later\\n       0\n",
       "23    Dunno lei... I might b eatin wif my frens... I...       0\n",
       "24                             Sorry, I'll call later\\n       0\n",
       "25    FREE entry into our £250 weekly comp just send...       1\n",
       "26    Say this slowly.? GOD,I LOVE YOU &amp; I NEED ...       0\n",
       "27     Do u noe how 2 send files between 2 computers?\\n       0\n",
       "28    Mmmmm ... I loved waking to your words this mo...       0\n",
       "29                   jay says he'll put in  &lt;#&gt;\\n       0\n",
       "...                                                 ...     ...\n",
       "971                       aathi..where are you dear..\\n       0\n",
       "972   Heart is empty without love.. Mind is empty wi...       0\n",
       "973   I think I‘m waiting for the same bus! Inform m...       0\n",
       "974                   You getting back any time soon?\\n       0\n",
       "975            , how's things? Just a quick question.\\n       0\n",
       "976   Night has ended for another day, morning has c...       0\n",
       "977   I can probably come by, everybody's done aroun...       0\n",
       "978   I got it before the new year cos yetunde said ...       0\n",
       "979   I can ask around but there's not a lot in term...       0\n",
       "980   Be sure to check your yahoo email. We sent pho...       0\n",
       "981                         What was she looking for?\\n       0\n",
       "982                          Wherre's my boytoy ? :-(\\n       0\n",
       "983   Do you want a NEW video phone750 anytime any n...       1\n",
       "984   Hello, my love! How goes that day ? I wish you...       0\n",
       "985   Tell my  bad character which u Dnt lik in me. ...       0\n",
       "986   No:-)i got rumour that you going to buy apartm...       0\n",
       "987                  Yeah, probably earlier than that\\n       0\n",
       "988                     Change windows logoff sound..\\n       0\n",
       "989               Still i have not checked it da. . .\\n       0\n",
       "990                            I'm also came to room.\\n       0\n",
       "991   Huh but i got lesson at 4 lei n i was thinkin ...       0\n",
       "992                                               Ok.\\n       0\n",
       "993   I will reach office around  &lt;DECIMAL&gt; . ...       0\n",
       "994                   Cool, text me when you head out\\n       0\n",
       "995   You are being contacted by our dating service ...       1\n",
       "996   Wan2 win a Meet+Greet with Westlife 4 U or a m...       1\n",
       "997   Happy birthday... May u find ur prince charmin...       0\n",
       "998   Oh, the grand is having a bit of a party but i...       0\n",
       "999   You said to me before i went back to bed that ...       0\n",
       "1000  I hope you arnt pissed off but id would really...       0\n",
       "\n",
       "[1001 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_target(data):\n",
    "    data[\"Target\"] = pd.Categorical(data[\"Target\"]).codes\n",
    "    return data\n",
    "    \n",
    "print(parse_target(train_data).head())\n",
    "parse_target(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn each message into a vector by using the dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, words_dic, max_amount=5):\n",
    "    feature_matrix = np.zeros((data.shape[0], len(words_dic)), dtype=int)\n",
    "    \n",
    "    messageID = 0\n",
    "    for line in data[\"Message\"]:\n",
    "        words = line.split(\" \")\n",
    "        for word in words:\n",
    "            for i, d in enumerate(words_dic):\n",
    "                if d[0] == word:\n",
    "                    feature_matrix[messageID, i] += 1\n",
    "                    if feature_matrix[messageID, i] >= max_amount:\n",
    "                        feature_matrix[messageID, i] = max_amount - 1\n",
    "        messageID += 1\n",
    "        \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 3000)\n",
      "(1001, 3000)\n"
     ]
    }
   ],
   "source": [
    "# Apply the function\n",
    "train_features = extract_features(train_data, words_dic)\n",
    "test_features = extract_features(test_data, words_dic)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Naive Bayes\n",
    "\n",
    "For this part, we will use the Bayes formula.\n",
    "* For each message, we write p(spam) the probability that this message is a spam, and p(x0) the probability that the word 0 is in that message.\n",
    "* p(spam | x0) = (p(x0 | spam) * p(spam)) / p(x0).\n",
    "* We know p(x0) and p(spam) trivially by counting how many instances of each are in our training set, and we can find p(x0 | spam) by looking for each word at how often they appear in spams.\n",
    "\n",
    "We thus have 3 steps to train a naive Bayes classifier for our spam filter :\n",
    "* Find p(X), for each word, the probability it is in a message.\n",
    "* Find p(spam), for each message, the probability it is a spam.\n",
    "* Find p(X | spam) : for each word, the probability it is in a spam.\n",
    "\n",
    "##### Find P(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13703425856464116\n"
     ]
    }
   ],
   "source": [
    "p_spam = train_data[\"Target\"][train_data[\"Target\"] == 1].count() / train_data.shape[0]\n",
    "print(p_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find p(X)\n",
    "* For each word, find the probability that it is x amount of time in any given message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our p_X.\n",
    "# It is a matrix with each word as a line and the amount of time it appears\n",
    "# in a message as a column\n",
    "def count_nb_instances_for_one_word(column):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return_value = np.zeros(5)\n",
    "    for number in column:\n",
    "        return_value[number] += 1\n",
    "        \n",
    "    return return_value\n",
    "\n",
    "# This function should have run using extract features\n",
    "def count_nb_instances_for_each_word(feature_matrix, max_amount=5):\n",
    "    \n",
    "    # Loop through each column of the messages\n",
    "    retour = np.apply_along_axis(count_nb_instances_for_one_word, axis=0, arr=feature_matrix)\n",
    "    \n",
    "    retour = np.transpose(retour)\n",
    "    \n",
    "    # Turn the matrice into probabi p\n",
    "    retour /= np.sum(retour[0, :])\n",
    "    \n",
    "    return retour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the above function to find the number of instances of each word in all messages in training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n"
     ]
    }
   ],
   "source": [
    "p_X = count_nb_instances_for_each_word(train_features)\n",
    "\n",
    "print(p_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70667667 0.22455614 0.05151288 0.01250313 0.00475119]\n"
     ]
    }
   ],
   "source": [
    "print(p_X[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [3 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[train_data[train_data[\"Target\"] == 1].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n",
      "[0.4379562  0.3850365  0.12591241 0.04562044 0.00547445]\n"
     ]
    }
   ],
   "source": [
    "p_X_spam = count_nb_instances_for_each_word(\\\n",
    "            train_features[train_data[train_data[\"Target\"] == 1].index])\n",
    "\n",
    "print(p_X_spam.shape)\n",
    "print(p_X_spam[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do now is to apply the formula thanks to np.apply_formula.please().no_really_I_dont_know_how_to_do_it(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This was our first version\n",
    "epsilon = 0.00000001\n",
    "# We now have all the elements to give to each word a probability\n",
    "p_spam_X = np.divide(p_X_spam * p_spam, p_X + epsilon)\n",
    "print(p_spam_X.shape)\n",
    "print(p_spam_X[0, :])\n",
    "\"\"\"\n",
    "p_spam_X = p_X_spam * p_spam\n",
    "\n",
    "p_ham = (1 - p_spam)\n",
    "\n",
    "p_X_ham = count_nb_instances_for_each_word(\\\n",
    "            train_features[train_data[train_data[\"Target\"] == 0].index])\n",
    "\n",
    "p_ham_X = p_X_ham * p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(p_spam_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We make the function to combine the probabilities of the words\n",
    "* By using the argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_message_argmax(message, p_spam_X, p_ham_X):\n",
    "    proba_spam = 1\n",
    "    proba_ham = 1\n",
    "    \n",
    "    for i, word in enumerate(message):\n",
    "        if word > 0:\n",
    "            proba_spam *= p_spam_X[i, word]\n",
    "            proba_ham *= p_ham_X[i, word]\n",
    "            \n",
    "    if proba_spam > proba_ham:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def full_argmax(feature_matrix, p_spam_X, p_ham_X):\n",
    "    \"\"\"\n",
    "    feature_matrix is a numpy matrix of shape (nb_examples, 3000)\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(one_message_argmax, 1, feature_matrix, p_spam_X, p_ham_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001,)\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Apply the functions\n",
    "results = full_argmax(test_features, p_spam_X, p_ham_X)\n",
    "\n",
    "print(results.shape)\n",
    "print(results[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try our model on the test_data\n",
    "* For each word, we have found the probability that its presence indicates the message is a spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target\n",
      "0                   Yup i've finished c ü there...\\n       0\n",
      "1             Remember to ask alex about his pizza\\n       0\n",
      "2                     No da..today also i forgot..\\n       0\n",
      "3  Ola would get back to you maybe not today but ...       0\n",
      "4  Fwiw the reason I'm only around when it's time...       0\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target\n",
      "0                   Yup i've finished c ü there...\\n       0\n",
      "1             Remember to ask alex about his pizza\\n       0\n",
      "2                     No da..today also i forgot..\\n       0\n",
      "3  Ola would get back to you maybe not today but ...       0\n",
      "4  Fwiw the reason I'm only around when it's time...       0\n"
     ]
    }
   ],
   "source": [
    "test_data = parse_target(test_data)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Loop through test_features, and find the mean of probabilities\\nscore_probas = np.zeros(test_data.shape[0])\\nfor i, line in enumerate(test_features):\\n\\n    word_count = 0\\n    for j, apparition in enumerate(line):\\n        if apparition > 0:\\n            # + 1 because multiple iteration of the same word\\n            # is already taken in consideration in p_spam_X\\n            word_count += 1\\n            if apparition >= p_spam_X.shape[1]:\\n                apparition = p_spam_X.shape[1] - 1\\n                \\n            score_probas[i] += p_spam_X[j, int(apparition)]\\n            \\n    score_probas[i] /= word_count\\n    \\nprint(score_probas.shape)\\nprint(score_probas[0])'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Loop through test_features, and find the mean of probabilities\n",
    "score_probas = np.zeros(test_data.shape[0])\n",
    "for i, line in enumerate(test_features):\n",
    "\n",
    "    word_count = 0\n",
    "    for j, apparition in enumerate(line):\n",
    "        if apparition > 0:\n",
    "            # + 1 because multiple iteration of the same word\n",
    "            # is already taken in consideration in p_spam_X\n",
    "            word_count += 1\n",
    "            if apparition >= p_spam_X.shape[1]:\n",
    "                apparition = p_spam_X.shape[1] - 1\n",
    "                \n",
    "            score_probas[i] += p_spam_X[j, int(apparition)]\n",
    "            \n",
    "    score_probas[i] /= word_count\n",
    "    \n",
    "print(score_probas.shape)\n",
    "print(score_probas[0])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Result'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Target  Result\n",
      "0                   Yup i've finished c ü there...\\n       0       0\n",
      "1             Remember to ask alex about his pizza\\n       0       0\n",
      "2                     No da..today also i forgot..\\n       0       0\n",
      "3  Ola would get back to you maybe not today but ...       0       0\n",
      "4  Fwiw the reason I'm only around when it's time...       0       0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 3 columns):\n",
      "Message    1001 non-null object\n",
      "Target     1001 non-null int8\n",
      "Result     1001 non-null int64\n",
      "dtypes: int64(1), int8(1), object(1)\n",
      "memory usage: 16.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Message  Target  Result\n",
      "14   U have won a nokia 6230 plus a free digital ca...       1       1\n",
      "25   FREE entry into our £250 weekly comp just send...       1       1\n",
      "48   Text82228>> Get more ringtones, logos and game...       1       1\n",
      "56   FreeMSG You have been awarded a FREE mini DIGI...       1       1\n",
      "58   This message is brought to you by GMW Ltd. and...       1       0\n",
      "74   Congrats 2 mobile 3G Videophones R yours. call...       1       1\n",
      "75   Your next amazing xxx PICSFREE1 video will be ...       1       0\n",
      "81   U are subscribed to the best Mobile Content Se...       1       0\n",
      "83   3 FREE TAROT TEXTS! Find out about your love l...       1       0\n",
      "90   Join the UK's horniest Dogging service and u c...       1       0\n",
      "96   Sunshine Quiz Wkly Q! Win a top Sony DVD playe...       1       1\n",
      "112  Knock Knock Txt whose there to 80082 to enter ...       1       1\n",
      "120  <Forwarded from 21870000>Hi - this is your Mai...       1       1\n",
      "126  FREE RING TONE just text \"POLYS\" to 87131. The...       1       1\n",
      "132  URGENT! Your mobile No 077xxx WON a £2,000 Bon...       1       1\n",
      "142  You are guaranteed the latest Nokia Phone, a 4...       1       1\n",
      "163  Hello darling how are you today? I would love ...       1       0\n",
      "164  8007 FREE for 1st week! No1 Nokia tone 4 ur mo...       1       1\n",
      "169  Wanna get laid 2nite? Want real Dogging locati...       1       1\n",
      "170  we tried to contact you re your response to ou...       1       1\n",
      "180  New Tones This week include: 1)McFly-All Ab..,...       1       1\n",
      "186  URGENT! We are trying to contact U. Todays dra...       1       1\n",
      "191  sports fans - get the latest sports news str* ...       1       1\n",
      "193  Urgent Urgent! We have 800 FREE flights to Eur...       1       0\n",
      "199                         FROM 88066 LOST £12 HELP\\n       1       0\n",
      "205  FreeMsg: Fancy a flirt? Reply DATE now & join ...       1       0\n",
      "208  Great NEW Offer - DOUBLE Mins & DOUBLE Txt on ...       1       1\n",
      "211  Hope you enjoyed your new content. text stop t...       1       0\n",
      "219  18 days to Euro2004 kickoff! U will be kept in...       1       1\n",
      "229  Urgent Please call 09066612661 from landline. ...       1       1\n",
      "..                                                 ...     ...     ...\n",
      "789  Someone U know has asked our dating service 2 ...       1       1\n",
      "790  Camera - You are awarded a SiPix Digital Camer...       1       1\n",
      "798  Todays Voda numbers ending 5226 are selected t...       1       1\n",
      "799  This message is free. Welcome to the new & imp...       1       0\n",
      "802         RCT' THNQ Adrian for U text. Rgds Vatian\\n       1       0\n",
      "816  FREE MESSAGE Activate your 500 FREE Text Messa...       1       1\n",
      "834  You are being contacted by our dating service ...       1       1\n",
      "860  Sorry I missed your call let's talk when you h...       1       0\n",
      "882  complimentary 4 STAR Ibiza Holiday or £10,000 ...       1       0\n",
      "885  FREE MSG:We billed your mobile number by mista...       1       0\n",
      "891  Please CALL 08712402972 immediately as there i...       1       0\n",
      "897  URGENT! Your Mobile number has been awarded wi...       1       1\n",
      "901  As a valued customer, I am pleased to advise y...       1       1\n",
      "909  Do you want a New Nokia 3510i colour phone Del...       1       1\n",
      "919  LIFE has never been this much fun and great un...       1       0\n",
      "920  Do you want a new Video phone? 600 anytime any...       1       0\n",
      "921  As a valued customer, I am pleased to advise y...       1       1\n",
      "922  Welcome! Please reply with your AGE and GENDER...       1       1\n",
      "923  Freemsg: 1-month unlimited free calls! Activat...       1       0\n",
      "924  Had your mobile 10 mths? Update to latest Oran...       1       1\n",
      "925  Am new 2 club & dont fink we met yet Will B gr...       1       0\n",
      "933  Camera - You are awarded a SiPix Digital Camer...       1       1\n",
      "942  Get a FREE mobile video player FREE movie. To ...       1       1\n",
      "943  Save money on wedding lingerie at www.bridal.p...       1       1\n",
      "960  Not heard from U4 a while. Call me now am here...       1       0\n",
      "963  Bloomberg -Message center +447797706009 Why wa...       1       0\n",
      "968  URGENT! We are trying to contact U. Todays dra...       1       1\n",
      "983  Do you want a NEW video phone750 anytime any n...       1       1\n",
      "995  You are being contacted by our dating service ...       1       1\n",
      "996  Wan2 win a Meet+Greet with Westlife 4 U or a m...       1       1\n",
      "\n",
      "[124 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[test_data['Target'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9500499500499501\n",
      "Precision : 0.9868421052631579\n",
      "Recall : 0.6048387096774194\n",
      "[[ 75.   1.]\n",
      " [ 49. 876.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/korax/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/home/korax/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/korax/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/home/korax/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(data):\n",
    "    \"\"\"\n",
    "    data is DataFrame containing the columns Target and Result\n",
    "    \"\"\"\n",
    "    confusion_matrix = np.zeros((2, 2))\n",
    "    \n",
    "    confusion_matrix[0, 0] = data\\\n",
    "    [data['Target'] == 1][data['Result'] == 1.0]['Target'].count()\n",
    "    \n",
    "    confusion_matrix[1, 1] = data\\\n",
    "    [data['Target'] == 0][data['Result'] == 0.0]['Target'].count()\n",
    "    \n",
    "    confusion_matrix[1, 0] = data\\\n",
    "    [data['Target'] == 1][data['Result'] == 0.0]['Target'].count()\n",
    "    \n",
    "    confusion_matrix[0, 1] = data\\\n",
    "    [data['Target'] == 0][data['Result'] == 1.0]['Target'].count()\n",
    "    \n",
    "    print(\"Accuracy : \",\\\n",
    "          (confusion_matrix[0, 0] + confusion_matrix[1, 1])/data.shape[0])\n",
    "    print(\"Precision :\",\\\n",
    "    (confusion_matrix[0, 0])/np.sum(confusion_matrix[0, :]))\n",
    "    print(\"Recall :\",\\\n",
    "    (confusion_matrix[0, 0])/np.sum(confusion_matrix[:, 0]))\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(test_data)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
